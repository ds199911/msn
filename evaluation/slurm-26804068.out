INFO:root:loaded params...
{   'data': {'image_folder': '/imagenet/', 'num_classes': 25, 'root_path': '.'},
    'logging': {   'folder': 'checkpoint/msn_logs/',
                   'pretrain_path': '/scratch/projects/shamoutlab/ds5749/multi-modal-msn/checkpoint/msn_fusion_logs/msn-experiment-fusion-128-latest.pth.tar',
                   'write_tag': 'msn-lineval-experiment-linear-eval-fusion-128'},
    'meta': {   'copy_data': False,
                'device': 'cuda:0',
                'load_checkpoint': True,
                'master_port': 8888,
                'model_name': 'deit_small',
                'training': True},
    'optimization': {   'epochs': 100,
                        'lr': 6.4,
                        'normalize': True,
                        'num_blocks': 1,
                        'weight_decay': 0.0}}
INFO:root:Running linear-evaluation
INFO:root:MIMICCXR cxr_ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/configs/eval/medfuse_fusion.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:initialized data-loader (ipe 333)
INFO:root:MIMICCXR cxr_ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/configs/eval/medfuse_fusion.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:initialized val data-loader (ipe 7)
INFO:root:key "fc.weight" could not be found in loaded state dict
INFO:root:key "fc.bias" could not be found in loaded state dict
INFO:root:loaded pretrained model with msg: _IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=['fc.fc1.weight', 'fc.fc1.bias', 'fc.bn1.weight', 'fc.bn1.bias', 'fc.bn1.running_mean', 'fc.bn1.running_var', 'fc.bn1.num_batches_tracked', 'fc.fc2.weight', 'fc.fc2.bias', 'fc.bn2.weight', 'fc.bn2.bias', 'fc.bn2.running_mean', 'fc.bn2.running_var', 'fc.bn2.num_batches_tracked', 'fc.fc3.weight', 'fc.fc3.bias'])
INFO:root:loaded pretrained encoder from epoch: 64 path: /scratch/projects/shamoutlab/ds5749/multi-modal-msn/checkpoint/msn_fusion_logs/msn-experiment-fusion-128-latest.pth.tar
INFO:root:Fusion(
  (ehr_model): LSTM(
    (layer0): LSTM(76, 128, batch_first=True)
    (dense_layer): Linear(in_features=128, out_features=128, bias=True)
  )
  (cxr_model): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
    (fc): Identity()
  )
  (projection): Linear(in_features=512, out_features=512, bias=True)
  (fc): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
INFO:root:putting model in eval mode
INFO:root:7871488
INFO:root:epoch: 0
INFO:root:epoch: 1
INFO:root:epoch: 2
INFO:root:epoch: 3
INFO:root:epoch: 4
INFO:root:epoch: 5
INFO:root:epoch: 6
INFO:root:epoch: 7
INFO:root:epoch: 8
INFO:root:epoch: 9
INFO:root:epoch: 10
INFO:root:epoch: 11
INFO:root:epoch: 12
INFO:root:epoch: 13
INFO:root:epoch: 14
INFO:root:epoch: 15
INFO:root:epoch: 16
INFO:root:epoch: 17
INFO:root:epoch: 18
INFO:root:epoch: 19
INFO:root:epoch: 20
INFO:root:epoch: 21
INFO:root:epoch: 22
INFO:root:epoch: 23
INFO:root:epoch: 24
INFO:root:epoch: 25
INFO:root:epoch: 26
INFO:root:epoch: 27
INFO:root:epoch: 28
INFO:root:epoch: 29
INFO:root:epoch: 30
INFO:root:epoch: 31
INFO:root:epoch: 32
INFO:root:epoch: 33
INFO:root:epoch: 34
INFO:root:epoch: 35
INFO:root:epoch: 36
INFO:root:epoch: 37
INFO:root:epoch: 38
INFO:root:epoch: 39
INFO:root:epoch: 40
INFO:root:epoch: 41
INFO:root:epoch: 42
INFO:root:epoch: 43
INFO:root:epoch: 44
INFO:root:epoch: 45
INFO:root:epoch: 46
INFO:root:epoch: 47
INFO:root:epoch: 48
INFO:root:epoch: 49
INFO:root:epoch: 50
INFO:root:epoch: 51
INFO:root:epoch: 52
INFO:root:epoch: 53
INFO:root:epoch: 54
INFO:root:epoch: 55
INFO:root:epoch: 56
INFO:root:epoch: 57
INFO:root:epoch: 58
INFO:root:epoch: 59
INFO:root:epoch: 60
INFO:root:epoch: 61
INFO:root:epoch: 62
INFO:root:epoch: 63
INFO:root:epoch: 64
INFO:root:epoch: 65
INFO:root:epoch: 66
INFO:root:epoch: 67
INFO:root:epoch: 68
INFO:root:epoch: 69
INFO:root:epoch: 70
INFO:root:epoch: 71
INFO:root:epoch: 72
INFO:root:epoch: 73
INFO:root:epoch: 74
INFO:root:epoch: 75
INFO:root:epoch: 76
INFO:root:epoch: 77
INFO:root:epoch: 78
INFO:root:epoch: 79
INFO:root:epoch: 80
INFO:root:epoch: 81
INFO:root:epoch: 82
INFO:root:epoch: 83
INFO:root:epoch: 84
INFO:root:epoch: 85
INFO:root:epoch: 86
INFO:root:epoch: 87
INFO:root:epoch: 88
INFO:root:epoch: 89
INFO:root:epoch: 90
INFO:root:epoch: 91
INFO:root:epoch: 92
INFO:root:epoch: 93
INFO:root:epoch: 94
INFO:root:epoch: 95
INFO:root:epoch: 96
INFO:root:epoch: 97
INFO:root:epoch: 98
INFO:root:epoch: 99
INFO:root:epoch: 100
INFO:root:epoch: 101
INFO:root:epoch: 102
INFO:root:epoch: 103
INFO:root:epoch: 104
INFO:root:epoch: 105
INFO:root:epoch: 106
INFO:root:epoch: 107
INFO:root:epoch: 108
INFO:root:epoch: 109
INFO:root:epoch: 110
INFO:root:epoch: 111
INFO:root:epoch: 112
INFO:root:epoch: 113
INFO:root:epoch: 114
INFO:root:epoch: 115
INFO:root:epoch: 116
INFO:root:epoch: 117
INFO:root:epoch: 118
INFO:root:epoch: 119
