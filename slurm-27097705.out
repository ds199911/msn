INFO:root:called-params configs/pretrain/msn_ehr_lstm.yaml
INFO:root:loaded params...
{   'criterion': {   'batch_size': 64,
                     'ent_weight': 0.0,
                     'final_sharpen': 0.25,
                     'me_max': True,
                     'memax_weight': 1.0,
                     'num_proto': 128,
                     'start_sharpen': 0.25,
                     'temperature': 0.1,
                     'use_ent': True,
                     'use_sinkhorn': True},
    'data': {   'color_jitter_strength': 0.5,
                'focal_size': 96,
                'focal_views': 10,
                'image_folder': '/imagenet/',
                'label_smoothing': 0.0,
                'modality': 'ehr',
                'num_workers': 10,
                'patch_drop': 0.15,
                'pin_mem': True,
                'rand_size': 224,
                'rand_views': 1,
                'root_path': '.'},
    'logging': {   'folder': 'checkpoint/msn_ehr_logs/',
                   'write_tag': 'msn-experiment-1'},
    'meta': {   'bottleneck': 1,
                'copy_data': False,
                'drop_path_rate': 0.0,
                'hidden_dim': 2048,
                'load_checkpoint': False,
                'model_name': 'deit_small',
                'output_dim': 256,
                'read_checkpoint': None,
                'use_bn': True,
                'use_fp16': False,
                'use_pred_head': False},
    'optimization': {   'clip_grad': 3.0,
                        'epochs': 1,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'lr': 0.001,
                        'start_lr': 0.0002,
                        'warmup': 15,
                        'weight_decay': 0.04}}
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for 1 nodes.
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:LSTM(
  (layer0): LSTM(76, 128, batch_first=True)
  (dense_layer): Linear(in_features=128, out_features=128, bias=True)
  (fc): Sequential(
    (fc1): Linear(in_features=128, out_features=2048, bias=True)
    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gelu1): GELU()
    (fc2): Linear(in_features=2048, out_features=2048, bias=True)
    (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gelu2): GELU()
    (fc3): Linear(in_features=2048, out_features=256, bias=True)
  )
)
INFO:root:making data transforms
INFO:root:MIMICCXR ehr fusion dataset
Traceback (most recent call last):
  File "main.py", line 84, in <module>
    args=(args.fname, num_gpus, args.devices))
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/main.py", line 67, in process_main
    return msn(params)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/msn_train.py", line 228, in main
    args=args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/data_manager.py", line 213, in init_ehr_data
    args.data_pairs = 'partial_ehr_cxr'
AttributeError: 'dict' object has no attribute 'data_pairs'

