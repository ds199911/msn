INFO:root:called-params configs/pretrain/msn_ehr_lstm.yaml
INFO:root:loaded params...
{   'criterion': {   'batch_size': 64,
                     'ent_weight': 0.0,
                     'final_sharpen': 0.25,
                     'me_max': True,
                     'memax_weight': 1.0,
                     'num_proto': 128,
                     'start_sharpen': 0.25,
                     'temperature': 0.1,
                     'use_ent': True,
                     'use_sinkhorn': True},
    'data': {   'color_jitter_strength': 0.5,
                'focal_size': 96,
                'focal_views': 10,
                'image_folder': '/imagenet/',
                'label_smoothing': 0.0,
                'modality': 'ehr',
                'num_workers': 10,
                'patch_drop': 0.15,
                'pin_mem': True,
                'rand_size': 224,
                'rand_views': 1,
                'root_path': '.'},
    'logging': {   'folder': 'checkpoint/msn_ehr_logs/',
                   'write_tag': 'msn-experiment-1'},
    'meta': {   'bottleneck': 1,
                'copy_data': False,
                'drop_path_rate': 0.0,
                'hidden_dim': 1024,
                'load_checkpoint': False,
                'model_name': 'deit_small',
                'output_dim': 128,
                'read_checkpoint': None,
                'use_bn': True,
                'use_fp16': False,
                'use_pred_head': False},
    'optimization': {   'clip_grad': 3.0,
                        'epochs': 1,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'lr': 0.001,
                        'start_lr': 0.0002,
                        'warmup': 15,
                        'weight_decay': 0.04}}
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for 1 nodes.
INFO:root:Running... (rank: 0/1)
INFO:root:Running ehr
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:LSTM(
  (layer0): LSTM(76, 128, batch_first=True)
  (dense_layer): Linear(in_features=128, out_features=128, bias=True)
  (fc): Sequential(
    (fc1): Linear(in_features=128, out_features=1024, bias=True)
    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gelu1): GELU()
    (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gelu2): GELU()
    (fc3): Linear(in_features=1024, out_features=128, bias=True)
  )
)
INFO:root:making data transforms
INFO:root:{'criterion': {'ent_weight': 0.0, 'final_sharpen': 0.25, 'me_max': True, 'memax_weight': 1.0, 'num_proto': 128, 'start_sharpen': 0.25, 'temperature': 0.1, 'batch_size': 64, 'use_ent': True, 'use_sinkhorn': True}, 'data': {'modality': 'ehr', 'color_jitter_strength': 0.5, 'pin_mem': True, 'num_workers': 10, 'image_folder': '/imagenet/', 'label_smoothing': 0.0, 'patch_drop': 0.15, 'rand_size': 224, 'focal_size': 96, 'rand_views': 1, 'focal_views': 10, 'root_path': '.'}, 'logging': {'folder': 'checkpoint/msn_ehr_logs/', 'write_tag': 'msn-experiment-1'}, 'meta': {'bottleneck': 1, 'copy_data': False, 'drop_path_rate': 0.0, 'hidden_dim': 1024, 'load_checkpoint': False, 'model_name': 'deit_small', 'output_dim': 128, 'read_checkpoint': None, 'use_bn': True, 'use_fp16': False, 'use_pred_head': False}, 'optimization': {'clip_grad': 3.0, 'epochs': 1, 'final_lr': 1e-06, 'final_weight_decay': 0.4, 'lr': 0.001, 'start_lr': 0.0002, 'warmup': 15, 'weight_decay': 0.04}}
INFO:root:MIMICCXR ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, devices=['cuda:0'], dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='configs/pretrain/msn_ehr_lstm.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, modality='ehr', mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:iterations per epoch: 666
INFO:root:Created prototypes: torch.Size([128, 128])
INFO:root:Requires grad: True
INFO:root:Using AdamW
INFO:root:Epoch 1
INFO:root:[1,     0] loss: 5.320 (5.024 0.296 4.528) (np: 13.0, max-t: 0.023) [wd: 4.00e-02] [lr: 2.00e-04] [mem: 5.56e+02] (403 ms; 14 ms)
INFO:root:[1,     0] grad_stats: [0.00e+00 0.00e+00] (1.00e+00, 7.02e+00)
INFO:root:[1,    10] loss: 4.922 (4.823 0.099 4.714) (np: 12.2, max-t: 0.024) [wd: 4.02e-02] [lr: 2.01e-04] [mem: 5.56e+02] (76 ms; 7 ms)
INFO:root:[1,    10] grad_stats: [0.00e+00 0.00e+00] (1.70e-01, 1.29e+00)
INFO:root:[1,    20] loss: 4.825 (4.766 0.060 4.739) (np: 12.4, max-t: 0.024) [wd: 4.06e-02] [lr: 2.02e-04] [mem: 8.06e+02] (71 ms; 10 ms)
INFO:root:[1,    20] grad_stats: [0.00e+00 0.00e+00] (2.44e-01, 1.16e+00)
INFO:root:[1,    30] loss: 4.762 (4.718 0.044 4.730) (np: 12.5, max-t: 0.024) [wd: 4.12e-02] [lr: 2.02e-04] [mem: 9.46e+02] (68 ms; 10 ms)
INFO:root:[1,    30] grad_stats: [0.00e+00 0.00e+00] (3.67e-01, 1.24e+00)
INFO:root:[1,    40] loss: 4.721 (4.686 0.035 4.717) (np: 12.5, max-t: 0.024) [wd: 4.22e-02] [lr: 2.03e-04] [mem: 9.46e+02] (65 ms; 10 ms)
INFO:root:[1,    40] grad_stats: [0.00e+00 0.00e+00] (1.71e-01, 7.35e-01)
INFO:root:[1,    50] loss: 4.681 (4.651 0.029 4.695) (np: 12.8, max-t: 0.025) [wd: 4.33e-02] [lr: 2.04e-04] [mem: 9.46e+02] (64 ms; 10 ms)
INFO:root:[1,    50] grad_stats: [0.00e+00 0.00e+00] (1.41e-01, 6.43e-01)
INFO:root:[1,    60] loss: 4.650 (4.624 0.026 4.677) (np: 13.0, max-t: 0.025) [wd: 4.48e-02] [lr: 2.05e-04] [mem: 9.46e+02] (62 ms; 10 ms)
INFO:root:[1,    60] grad_stats: [0.00e+00 0.00e+00] (1.87e-01, 8.67e-01)
INFO:root:[1,    70] loss: 4.623 (4.600 0.023 4.656) (np: 12.9, max-t: 0.026) [wd: 4.64e-02] [lr: 2.06e-04] [mem: 9.46e+02] (62 ms; 10 ms)
INFO:root:[1,    70] grad_stats: [0.00e+00 0.00e+00] (1.89e-01, 8.47e-01)
INFO:root:[1,    80] loss: 4.596 (4.574 0.021 4.637) (np: 13.0, max-t: 0.026) [wd: 4.84e-02] [lr: 2.06e-04] [mem: 9.46e+02] (61 ms; 10 ms)
INFO:root:[1,    80] grad_stats: [0.00e+00 0.00e+00] (3.25e-01, 1.11e+00)
INFO:root:[1,    90] loss: 4.571 (4.551 0.020 4.618) (np: 13.1, max-t: 0.026) [wd: 5.05e-02] [lr: 2.07e-04] [mem: 9.46e+02] (62 ms; 10 ms)
INFO:root:[1,    90] grad_stats: [0.00e+00 0.00e+00] (3.09e-01, 1.26e+00)
INFO:root:[1,   100] loss: 4.547 (4.528 0.019 4.601) (np: 13.3, max-t: 0.027) [wd: 5.29e-02] [lr: 2.08e-04] [mem: 9.46e+02] (63 ms; 10 ms)
INFO:root:[1,   100] grad_stats: [0.00e+00 0.00e+00] (6.72e-01, 2.12e+00)
INFO:root:[1,   110] loss: 4.526 (4.506 0.020 4.583) (np: 13.3, max-t: 0.027) [wd: 5.56e-02] [lr: 2.09e-04] [mem: 9.46e+02] (62 ms; 10 ms)
INFO:root:[1,   110] grad_stats: [0.00e+00 0.00e+00] (8.47e-01, 2.75e+00)
INFO:root:[1,   120] loss: 4.505 (4.485 0.019 4.567) (np: 13.5, max-t: 0.027) [wd: 5.85e-02] [lr: 2.10e-04] [mem: 9.46e+02] (62 ms; 10 ms)
INFO:root:[1,   120] grad_stats: [0.00e+00 0.00e+00] (7.25e-01, 2.51e+00)
INFO:root:[1,   130] loss: 4.485 (4.466 0.019 4.550) (np: 13.7, max-t: 0.028) [wd: 6.16e-02] [lr: 2.10e-04] [mem: 9.46e+02] (62 ms; 10 ms)
INFO:root:[1,   130] grad_stats: [0.00e+00 0.00e+00] (3.01e-01, 1.43e+00)
INFO:root:[1,   140] loss: 4.463 (4.444 0.019 4.534) (np: 13.9, max-t: 0.028) [wd: 6.49e-02] [lr: 2.11e-04] [mem: 9.46e+02] (61 ms; 10 ms)
INFO:root:[1,   140] grad_stats: [0.00e+00 0.00e+00] (3.70e-01, 1.21e+00)
INFO:root:[1,   150] loss: 4.441 (4.423 0.018 4.517) (np: 14.0, max-t: 0.028) [wd: 6.85e-02] [lr: 2.12e-04] [mem: 9.46e+02] (62 ms; 10 ms)
INFO:root:[1,   150] grad_stats: [0.00e+00 0.00e+00] (2.73e-01, 1.07e+00)
INFO:root:[1,   160] loss: 4.420 (4.402 0.018 4.500) (np: 14.2, max-t: 0.028) [wd: 7.23e-02] [lr: 2.13e-04] [mem: 9.54e+02] (62 ms; 10 ms)
INFO:root:[1,   160] grad_stats: [0.00e+00 0.00e+00] (3.11e-01, 1.19e+00)
INFO:root:[1,   170] loss: 4.398 (4.381 0.017 4.482) (np: 14.4, max-t: 0.029) [wd: 7.62e-02] [lr: 2.14e-04] [mem: 9.54e+02] (62 ms; 10 ms)
INFO:root:[1,   170] grad_stats: [0.00e+00 0.00e+00] (2.99e-01, 1.20e+00)
INFO:root:[1,   180] loss: 4.378 (4.360 0.018 4.465) (np: 14.6, max-t: 0.029) [wd: 8.04e-02] [lr: 2.14e-04] [mem: 9.54e+02] (62 ms; 10 ms)
INFO:root:[1,   180] grad_stats: [0.00e+00 0.00e+00] (7.19e-01, 2.33e+00)
INFO:root:[1,   190] loss: 4.360 (4.342 0.018 4.449) (np: 14.8, max-t: 0.029) [wd: 8.48e-02] [lr: 2.15e-04] [mem: 9.54e+02] (62 ms; 11 ms)
INFO:root:[1,   190] grad_stats: [0.00e+00 0.00e+00] (2.94e-01, 1.12e+00)
INFO:root:[1,   200] loss: 4.344 (4.325 0.019 4.433) (np: 15.0, max-t: 0.030) [wd: 8.94e-02] [lr: 2.16e-04] [mem: 9.54e+02] (62 ms; 10 ms)
INFO:root:[1,   200] grad_stats: [0.00e+00 0.00e+00] (4.56e-01, 1.59e+00)
INFO:root:[1,   210] loss: 4.326 (4.307 0.019 4.417) (np: 15.2, max-t: 0.030) [wd: 9.42e-02] [lr: 2.17e-04] [mem: 9.54e+02] (62 ms; 10 ms)
INFO:root:[1,   210] grad_stats: [0.00e+00 0.00e+00] (4.69e-01, 1.65e+00)
INFO:root:[1,   220] loss: 4.308 (4.289 0.019 4.402) (np: 15.3, max-t: 0.030) [wd: 9.91e-02] [lr: 2.18e-04] [mem: 9.54e+02] (62 ms; 11 ms)
INFO:root:[1,   220] grad_stats: [0.00e+00 0.00e+00] (1.94e-01, 9.82e-01)
INFO:root:[1,   230] loss: 4.291 (4.272 0.019 4.387) (np: 15.5, max-t: 0.030) [wd: 1.04e-01] [lr: 2.18e-04] [mem: 9.54e+02] (62 ms; 10 ms)
INFO:root:[1,   230] grad_stats: [0.00e+00 0.00e+00] (4.16e-01, 1.44e+00)
INFO:root:[1,   240] loss: 4.275 (4.255 0.019 4.371) (np: 15.6, max-t: 0.031) [wd: 1.10e-01] [lr: 2.19e-04] [mem: 9.54e+02] (61 ms; 10 ms)
INFO:root:[1,   240] grad_stats: [0.00e+00 0.00e+00] (5.02e-01, 1.80e+00)
INFO:root:[1,   250] loss: 4.260 (4.240 0.020 4.357) (np: 15.8, max-t: 0.031) [wd: 1.15e-01] [lr: 2.20e-04] [mem: 9.54e+02] (61 ms; 10 ms)
INFO:root:[1,   250] grad_stats: [0.00e+00 0.00e+00] (6.81e-01, 2.23e+00)
INFO:root:[1,   260] loss: 4.244 (4.224 0.020 4.342) (np: 16.0, max-t: 0.031) [wd: 1.21e-01] [lr: 2.21e-04] [mem: 9.54e+02] (61 ms; 10 ms)
INFO:root:[1,   260] grad_stats: [0.00e+00 0.00e+00] (3.70e-01, 1.66e+00)
INFO:root:[1,   270] loss: 4.230 (4.209 0.021 4.328) (np: 16.1, max-t: 0.031) [wd: 1.26e-01] [lr: 2.22e-04] [mem: 9.54e+02] (61 ms; 10 ms)
INFO:root:[1,   270] grad_stats: [0.00e+00 0.00e+00] (9.21e-01, 2.62e+00)
INFO:root:[1,   280] loss: 4.217 (4.196 0.021 4.315) (np: 16.3, max-t: 0.032) [wd: 1.32e-01] [lr: 2.23e-04] [mem: 9.54e+02] (61 ms; 10 ms)
INFO:root:[1,   280] grad_stats: [0.00e+00 0.00e+00] (4.38e-01, 1.71e+00)
INFO:root:[1,   290] loss: 4.203 (4.181 0.021 4.302) (np: 16.4, max-t: 0.032) [wd: 1.38e-01] [lr: 2.23e-04] [mem: 9.54e+02] (61 ms; 10 ms)
INFO:root:[1,   290] grad_stats: [0.00e+00 0.00e+00] (4.78e-01, 1.95e+00)
INFO:root:[1,   300] loss: 4.190 (4.168 0.022 4.290) (np: 16.5, max-t: 0.032) [wd: 1.44e-01] [lr: 2.24e-04] [mem: 9.54e+02] (60 ms; 10 ms)
INFO:root:[1,   300] grad_stats: [0.00e+00 0.00e+00] (5.13e-01, 1.73e+00)
INFO:root:[1,   310] loss: 4.177 (4.155 0.022 4.277) (np: 16.6, max-t: 0.032) [wd: 1.50e-01] [lr: 2.25e-04] [mem: 9.54e+02] (60 ms; 10 ms)
INFO:root:[1,   310] grad_stats: [0.00e+00 0.00e+00] (2.80e-01, 1.13e+00)
INFO:root:[1,   320] loss: 4.164 (4.142 0.022 4.264) (np: 16.7, max-t: 0.033) [wd: 1.57e-01] [lr: 2.26e-04] [mem: 9.54e+02] (60 ms; 10 ms)
INFO:root:[1,   320] grad_stats: [0.00e+00 0.00e+00] (7.63e-01, 2.19e+00)
INFO:root:[1,   330] loss: 4.152 (4.130 0.022 4.253) (np: 16.8, max-t: 0.033) [wd: 1.63e-01] [lr: 2.27e-04] [mem: 9.54e+02] (60 ms; 10 ms)
INFO:root:[1,   330] grad_stats: [0.00e+00 0.00e+00] (7.35e-01, 2.16e+00)
INFO:root:[1,   340] loss: 4.141 (4.118 0.023 4.241) (np: 16.9, max-t: 0.033) [wd: 1.70e-01] [lr: 2.27e-04] [mem: 9.54e+02] (60 ms; 10 ms)
INFO:root:[1,   340] grad_stats: [0.00e+00 0.00e+00] (3.12e-01, 1.22e+00)
INFO:root:[1,   350] loss: 4.129 (4.106 0.023 4.230) (np: 16.9, max-t: 0.034) [wd: 1.76e-01] [lr: 2.28e-04] [mem: 1.23e+03] (60 ms; 10 ms)
INFO:root:[1,   350] grad_stats: [0.00e+00 0.00e+00] (6.95e-01, 2.06e+00)
INFO:root:[1,   360] loss: 4.117 (4.094 0.024 4.219) (np: 17.0, max-t: 0.034) [wd: 1.83e-01] [lr: 2.29e-04] [mem: 1.23e+03] (60 ms; 11 ms)
INFO:root:[1,   360] grad_stats: [0.00e+00 0.00e+00] (7.07e-01, 1.98e+00)
INFO:root:[1,   370] loss: 4.106 (4.082 0.024 4.207) (np: 17.1, max-t: 0.034) [wd: 1.90e-01] [lr: 2.30e-04] [mem: 1.23e+03] (60 ms; 11 ms)
INFO:root:[1,   370] grad_stats: [0.00e+00 0.00e+00] (8.80e-01, 2.91e+00)
INFO:root:[1,   380] loss: 4.096 (4.072 0.024 4.197) (np: 17.2, max-t: 0.035) [wd: 1.96e-01] [lr: 2.31e-04] [mem: 1.43e+03] (61 ms; 11 ms)
INFO:root:[1,   380] grad_stats: [0.00e+00 0.00e+00] (9.04e-01, 2.65e+00)
INFO:root:[1,   390] loss: 4.086 (4.062 0.025 4.187) (np: 17.3, max-t: 0.035) [wd: 2.03e-01] [lr: 2.31e-04] [mem: 1.43e+03] (61 ms; 11 ms)
INFO:root:[1,   390] grad_stats: [0.00e+00 0.00e+00] (4.43e-01, 1.48e+00)
INFO:root:[1,   400] loss: 4.078 (4.052 0.026 4.178) (np: 17.4, max-t: 0.035) [wd: 2.10e-01] [lr: 2.32e-04] [mem: 1.43e+03] (60 ms; 11 ms)
INFO:root:[1,   400] grad_stats: [0.00e+00 0.00e+00] (3.63e-01, 1.30e+00)
INFO:root:[1,   410] loss: 4.069 (4.043 0.026 4.169) (np: 17.5, max-t: 0.035) [wd: 2.17e-01] [lr: 2.33e-04] [mem: 1.43e+03] (60 ms; 11 ms)
INFO:root:[1,   410] grad_stats: [0.00e+00 0.00e+00] (5.08e-01, 1.62e+00)
INFO:root:[1,   420] loss: 4.061 (4.034 0.027 4.160) (np: 17.6, max-t: 0.036) [wd: 2.23e-01] [lr: 2.34e-04] [mem: 1.43e+03] (60 ms; 11 ms)
INFO:root:[1,   420] grad_stats: [0.00e+00 0.00e+00] (2.30e-01, 1.16e+00)
INFO:root:[1,   430] loss: 4.051 (4.024 0.027 4.151) (np: 17.7, max-t: 0.036) [wd: 2.30e-01] [lr: 2.35e-04] [mem: 1.43e+03] (61 ms; 11 ms)
INFO:root:[1,   430] grad_stats: [0.00e+00 0.00e+00] (2.59e-01, 9.71e-01)
INFO:root:[1,   440] loss: 4.043 (4.015 0.027 4.142) (np: 17.8, max-t: 0.036) [wd: 2.37e-01] [lr: 2.35e-04] [mem: 1.43e+03] (61 ms; 11 ms)
INFO:root:[1,   440] grad_stats: [0.00e+00 0.00e+00] (5.86e-01, 1.69e+00)
INFO:root:[1,   450] loss: 4.035 (4.007 0.028 4.134) (np: 17.9, max-t: 0.037) [wd: 2.44e-01] [lr: 2.36e-04] [mem: 1.43e+03] (61 ms; 11 ms)
INFO:root:[1,   450] grad_stats: [0.00e+00 0.00e+00] (7.49e-01, 2.12e+00)
INFO:root:[1,   460] loss: 4.027 (3.999 0.028 4.125) (np: 17.9, max-t: 0.037) [wd: 2.50e-01] [lr: 2.37e-04] [mem: 1.43e+03] (62 ms; 11 ms)
INFO:root:[1,   460] grad_stats: [0.00e+00 0.00e+00] (6.61e-01, 1.92e+00)
INFO:root:[1,   470] loss: 4.019 (3.991 0.029 4.117) (np: 18.0, max-t: 0.037) [wd: 2.57e-01] [lr: 2.38e-04] [mem: 1.43e+03] (62 ms; 11 ms)
INFO:root:[1,   470] grad_stats: [0.00e+00 0.00e+00] (2.42e-01, 9.58e-01)
INFO:root:[1,   480] loss: 4.012 (3.983 0.030 4.109) (np: 18.0, max-t: 0.037) [wd: 2.64e-01] [lr: 2.39e-04] [mem: 1.43e+03] (62 ms; 11 ms)
INFO:root:[1,   480] grad_stats: [0.00e+00 0.00e+00] (4.03e-01, 1.24e+00)
INFO:root:[1,   490] loss: 4.005 (3.975 0.030 4.101) (np: 18.1, max-t: 0.037) [wd: 2.70e-01] [lr: 2.39e-04] [mem: 1.60e+03] (62 ms; 11 ms)
INFO:root:[1,   490] grad_stats: [0.00e+00 0.00e+00] (6.79e-01, 1.96e+00)
INFO:root:[1,   500] loss: 3.997 (3.967 0.030 4.093) (np: 18.2, max-t: 0.038) [wd: 2.77e-01] [lr: 2.40e-04] [mem: 1.60e+03] (63 ms; 11 ms)
INFO:root:[1,   500] grad_stats: [0.00e+00 0.00e+00] (2.60e-01, 1.05e+00)
INFO:root:[1,   510] loss: 3.991 (3.960 0.031 4.086) (np: 18.3, max-t: 0.038) [wd: 2.83e-01] [lr: 2.41e-04] [mem: 1.60e+03] (63 ms; 11 ms)
INFO:root:[1,   510] grad_stats: [0.00e+00 0.00e+00] (5.92e-01, 1.87e+00)
INFO:root:[1,   520] loss: 3.983 (3.952 0.031 4.078) (np: 18.4, max-t: 0.038) [wd: 2.90e-01] [lr: 2.42e-04] [mem: 1.60e+03] (63 ms; 11 ms)
INFO:root:[1,   520] grad_stats: [0.00e+00 0.00e+00] (2.78e-01, 1.06e+00)
INFO:root:[1,   530] loss: 3.977 (3.946 0.031 4.071) (np: 18.4, max-t: 0.039) [wd: 2.96e-01] [lr: 2.43e-04] [mem: 1.60e+03] (63 ms; 11 ms)
INFO:root:[1,   530] grad_stats: [0.00e+00 0.00e+00] (1.04e+00, 3.14e+00)
INFO:root:[1,   540] loss: 3.970 (3.939 0.032 4.063) (np: 18.5, max-t: 0.039) [wd: 3.02e-01] [lr: 2.43e-04] [mem: 1.60e+03] (63 ms; 11 ms)
INFO:root:[1,   540] grad_stats: [0.00e+00 0.00e+00] (9.53e-01, 2.87e+00)
INFO:root:[1,   550] loss: 3.963 (3.931 0.032 4.055) (np: 18.6, max-t: 0.039) [wd: 3.08e-01] [lr: 2.44e-04] [mem: 1.60e+03] (63 ms; 11 ms)
INFO:root:[1,   550] grad_stats: [0.00e+00 0.00e+00] (6.55e-01, 1.83e+00)
INFO:root:[1,   560] loss: 3.957 (3.925 0.033 4.049) (np: 18.6, max-t: 0.039) [wd: 3.14e-01] [lr: 2.45e-04] [mem: 1.60e+03] (63 ms; 11 ms)
INFO:root:[1,   560] grad_stats: [0.00e+00 0.00e+00] (2.51e-01, 1.16e+00)
/ext3/medfuse/lib/python3.6/site-packages/torch/nn/modules/rnn.py:683: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448272031/work/aten/src/ATen/native/cudnn/RNN.cpp:924.)
  self.num_layers, self.dropout, self.training, self.bidirectional)
Traceback (most recent call last):
  File "main.py", line 84, in <module>
    args=(args.fname, num_gpus, args.devices, args.modality, args))
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/main.py", line 69, in process_main
    return msn(params, medfuse_args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/msn_train.py", line 336, in main
    for itr, data in enumerate(unsupervised_loader):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_dataset.py", line 98, in __getitem__
    data[i] = self.discretizer.transform(data[i], end=ts)[0]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 108, in transform
    write(data, bin_id, channel, row[j], begin_pos)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 81, in write
    category_id = self._possible_values[channel].index(value)
ValueError: '4 S' is not in list

