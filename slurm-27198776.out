INFO:root:called-params configs/pretrain/msn_ehr_lstm.yaml
INFO:root:loaded params...
{   'criterion': {   'batch_size': 64,
                     'ent_weight': 0.0,
                     'final_sharpen': 0.25,
                     'me_max': True,
                     'memax_weight': 1.0,
                     'num_proto': 128,
                     'start_sharpen': 0.25,
                     'temperature': 0.1,
                     'use_ent': True,
                     'use_sinkhorn': True},
    'data': {   'color_jitter_strength': 0.5,
                'focal_size': 96,
                'focal_views': 10,
                'image_folder': '/imagenet/',
                'label_smoothing': 0.0,
                'modality': 'ehr',
                'num_workers': 10,
                'patch_drop': 0.15,
                'pin_mem': True,
                'rand_size': 224,
                'rand_views': 1,
                'root_path': '.'},
    'logging': {   'folder': 'checkpoint/msn_ehr_logs/',
                   'write_tag': 'msn-experiment-1'},
    'meta': {   'bottleneck': 1,
                'copy_data': False,
                'drop_path_rate': 0.0,
                'hidden_dim': 1024,
                'load_checkpoint': False,
                'model_name': 'deit_small',
                'output_dim': 128,
                'read_checkpoint': None,
                'use_bn': True,
                'use_fp16': False,
                'use_pred_head': False},
    'optimization': {   'clip_grad': 3.0,
                        'epochs': 1,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'lr': 0.001,
                        'start_lr': 0.0002,
                        'warmup': 15,
                        'weight_decay': 0.04}}
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for 1 nodes.
INFO:root:Running... (rank: 0/1)
INFO:root:Running ehr
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:LSTM(
  (layer0): LSTM(76, 128, batch_first=True)
  (dense_layer): Linear(in_features=128, out_features=128, bias=True)
  (fc): Sequential(
    (fc1): Linear(in_features=128, out_features=1024, bias=True)
    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gelu1): GELU()
    (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gelu2): GELU()
    (fc3): Linear(in_features=1024, out_features=128, bias=True)
  )
)
INFO:root:making data transforms
INFO:root:{'criterion': {'ent_weight': 0.0, 'final_sharpen': 0.25, 'me_max': True, 'memax_weight': 1.0, 'num_proto': 128, 'start_sharpen': 0.25, 'temperature': 0.1, 'batch_size': 64, 'use_ent': True, 'use_sinkhorn': True}, 'data': {'modality': 'ehr', 'color_jitter_strength': 0.5, 'pin_mem': True, 'num_workers': 10, 'image_folder': '/imagenet/', 'label_smoothing': 0.0, 'patch_drop': 0.15, 'rand_size': 224, 'focal_size': 96, 'rand_views': 1, 'focal_views': 10, 'root_path': '.'}, 'logging': {'folder': 'checkpoint/msn_ehr_logs/', 'write_tag': 'msn-experiment-1'}, 'meta': {'bottleneck': 1, 'copy_data': False, 'drop_path_rate': 0.0, 'hidden_dim': 1024, 'load_checkpoint': False, 'model_name': 'deit_small', 'output_dim': 128, 'read_checkpoint': None, 'use_bn': True, 'use_fp16': False, 'use_pred_head': False}, 'optimization': {'clip_grad': 3.0, 'epochs': 1, 'final_lr': 1e-06, 'final_weight_decay': 0.4, 'lr': 0.001, 'start_lr': 0.0002, 'warmup': 15, 'weight_decay': 0.04}}
INFO:root:MIMICCXR ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, devices=['cuda:0'], dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='configs/pretrain/msn_ehr_lstm.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, modality='ehr', mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:iterations per epoch: 666
INFO:root:Created prototypes: torch.Size([128, 128])
INFO:root:Requires grad: True
INFO:root:Using AdamW
INFO:root:Epoch 1
INFO:root:[1,     0] loss: 5.302 (5.009 0.292 4.529) (np: 24.0, max-t: 0.027) [wd: 4.00e-02] [lr: 2.00e-04] [mem: 5.56e+02] (425 ms; 14 ms)
INFO:root:[1,     0] grad_stats: [0.00e+00 0.00e+00] (9.82e-01, 6.96e+00)
INFO:root:[1,    10] loss: 4.902 (4.804 0.099 4.711) (np: 26.4, max-t: 0.029) [wd: 4.02e-02] [lr: 2.01e-04] [mem: 5.56e+02] (88 ms; 8 ms)
INFO:root:[1,    10] grad_stats: [0.00e+00 0.00e+00] (1.87e-01, 1.37e+00)
INFO:root:[1,    20] loss: 4.805 (4.745 0.059 4.735) (np: 27.2, max-t: 0.029) [wd: 4.06e-02] [lr: 2.02e-04] [mem: 8.06e+02] (74 ms; 10 ms)
INFO:root:[1,    20] grad_stats: [0.00e+00 0.00e+00] (2.66e-01, 1.29e+00)
INFO:root:[1,    30] loss: 4.738 (4.695 0.044 4.722) (np: 27.3, max-t: 0.031) [wd: 4.12e-02] [lr: 2.02e-04] [mem: 9.46e+02] (73 ms; 10 ms)
INFO:root:[1,    30] grad_stats: [0.00e+00 0.00e+00] (4.06e-01, 1.46e+00)
INFO:root:[1,    40] loss: 4.696 (4.660 0.035 4.707) (np: 27.9, max-t: 0.032) [wd: 4.22e-02] [lr: 2.03e-04] [mem: 9.46e+02] (69 ms; 11 ms)
INFO:root:[1,    40] grad_stats: [0.00e+00 0.00e+00] (2.39e-01, 1.03e+00)
INFO:root:[1,    50] loss: 4.656 (4.626 0.030 4.683) (np: 28.6, max-t: 0.032) [wd: 4.33e-02] [lr: 2.04e-04] [mem: 9.46e+02] (65 ms; 10 ms)
INFO:root:[1,    50] grad_stats: [0.00e+00 0.00e+00] (2.16e-01, 9.01e-01)
INFO:root:[1,    60] loss: 4.625 (4.599 0.026 4.665) (np: 28.7, max-t: 0.033) [wd: 4.48e-02] [lr: 2.05e-04] [mem: 9.46e+02] (63 ms; 10 ms)
INFO:root:[1,    60] grad_stats: [0.00e+00 0.00e+00] (3.12e-01, 1.33e+00)
INFO:root:[1,    70] loss: 4.599 (4.575 0.024 4.645) (np: 28.9, max-t: 0.033) [wd: 4.64e-02] [lr: 2.06e-04] [mem: 9.46e+02] (63 ms; 10 ms)
INFO:root:[1,    70] grad_stats: [0.00e+00 0.00e+00] (3.53e-01, 1.73e+00)
INFO:root:[1,    80] loss: 4.572 (4.550 0.022 4.626) (np: 29.2, max-t: 0.034) [wd: 4.84e-02] [lr: 2.06e-04] [mem: 9.46e+02] (62 ms; 10 ms)
INFO:root:[1,    80] grad_stats: [0.00e+00 0.00e+00] (3.54e-01, 1.67e+00)
INFO:root:[1,    90] loss: 4.548 (4.527 0.021 4.607) (np: 29.4, max-t: 0.034) [wd: 5.05e-02] [lr: 2.07e-04] [mem: 9.46e+02] (61 ms; 10 ms)
INFO:root:[1,    90] grad_stats: [0.00e+00 0.00e+00] (4.07e-01, 1.87e+00)
INFO:root:[1,   100] loss: 4.525 (4.504 0.021 4.591) (np: 29.6, max-t: 0.035) [wd: 5.29e-02] [lr: 2.08e-04] [mem: 9.46e+02] (60 ms; 10 ms)
INFO:root:[1,   100] grad_stats: [0.00e+00 0.00e+00] (8.19e-01, 2.90e+00)
INFO:root:[1,   110] loss: 4.503 (4.483 0.021 4.574) (np: 29.8, max-t: 0.036) [wd: 5.56e-02] [lr: 2.09e-04] [mem: 9.46e+02] (60 ms; 10 ms)
INFO:root:[1,   110] grad_stats: [0.00e+00 0.00e+00] (9.36e-01, 3.52e+00)
INFO:root:[1,   120] loss: 4.482 (4.462 0.021 4.558) (np: 30.1, max-t: 0.037) [wd: 5.85e-02] [lr: 2.10e-04] [mem: 9.46e+02] (59 ms; 10 ms)
INFO:root:[1,   120] grad_stats: [0.00e+00 0.00e+00] (8.05e-01, 3.17e+00)
INFO:root:[1,   130] loss: 4.462 (4.442 0.021 4.542) (np: 30.5, max-t: 0.037) [wd: 6.16e-02] [lr: 2.10e-04] [mem: 9.46e+02] (60 ms; 10 ms)
INFO:root:[1,   130] grad_stats: [0.00e+00 0.00e+00] (4.25e-01, 2.17e+00)
INFO:root:[1,   140] loss: 4.439 (4.419 0.020 4.526) (np: 30.7, max-t: 0.038) [wd: 6.49e-02] [lr: 2.11e-04] [mem: 9.46e+02] (59 ms; 10 ms)
INFO:root:[1,   140] grad_stats: [0.00e+00 0.00e+00] (5.90e-01, 2.40e+00)
INFO:root:[1,   150] loss: 4.418 (4.398 0.020 4.510) (np: 31.0, max-t: 0.039) [wd: 6.85e-02] [lr: 2.12e-04] [mem: 9.46e+02] (59 ms; 10 ms)
INFO:root:[1,   150] grad_stats: [0.00e+00 0.00e+00] (6.70e-01, 3.07e+00)
INFO:root:[1,   160] loss: 4.398 (4.378 0.019 4.494) (np: 31.3, max-t: 0.039) [wd: 7.23e-02] [lr: 2.13e-04] [mem: 9.54e+02] (59 ms; 10 ms)
INFO:root:[1,   160] grad_stats: [0.00e+00 0.00e+00] (6.22e-01, 2.58e+00)
INFO:root:[1,   170] loss: 4.377 (4.358 0.019 4.478) (np: 31.7, max-t: 0.040) [wd: 7.62e-02] [lr: 2.14e-04] [mem: 9.54e+02] (59 ms; 10 ms)
INFO:root:[1,   170] grad_stats: [0.00e+00 0.00e+00] (5.69e-01, 2.43e+00)
INFO:root:[1,   180] loss: 4.357 (4.337 0.020 4.462) (np: 32.1, max-t: 0.041) [wd: 8.04e-02] [lr: 2.14e-04] [mem: 9.54e+02] (59 ms; 11 ms)
INFO:root:[1,   180] grad_stats: [0.00e+00 0.00e+00] (8.67e-01, 3.16e+00)
INFO:root:[1,   190] loss: 4.339 (4.319 0.020 4.446) (np: 32.3, max-t: 0.042) [wd: 8.48e-02] [lr: 2.15e-04] [mem: 9.54e+02] (59 ms; 11 ms)
INFO:root:[1,   190] grad_stats: [0.00e+00 0.00e+00] (7.04e-01, 2.94e+00)
INFO:root:[1,   200] loss: 4.321 (4.301 0.020 4.431) (np: 32.7, max-t: 0.042) [wd: 8.94e-02] [lr: 2.16e-04] [mem: 9.54e+02] (58 ms; 10 ms)
INFO:root:[1,   200] grad_stats: [0.00e+00 0.00e+00] (7.14e-01, 2.72e+00)
INFO:root:[1,   210] loss: 4.302 (4.282 0.020 4.416) (np: 32.9, max-t: 0.043) [wd: 9.42e-02] [lr: 2.17e-04] [mem: 9.54e+02] (58 ms; 11 ms)
INFO:root:[1,   210] grad_stats: [0.00e+00 0.00e+00] (8.56e-01, 3.33e+00)
INFO:root:[1,   220] loss: 4.284 (4.263 0.021 4.400) (np: 33.2, max-t: 0.044) [wd: 9.91e-02] [lr: 2.18e-04] [mem: 9.54e+02] (58 ms; 11 ms)
INFO:root:[1,   220] grad_stats: [0.00e+00 0.00e+00] (5.82e-01, 2.42e+00)
INFO:root:[1,   230] loss: 4.266 (4.245 0.021 4.386) (np: 33.4, max-t: 0.045) [wd: 1.04e-01] [lr: 2.18e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   230] grad_stats: [0.00e+00 0.00e+00] (7.40e-01, 2.93e+00)
INFO:root:[1,   240] loss: 4.248 (4.227 0.021 4.371) (np: 33.7, max-t: 0.046) [wd: 1.10e-01] [lr: 2.19e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   240] grad_stats: [0.00e+00 0.00e+00] (1.17e+00, 4.05e+00)
INFO:root:[1,   250] loss: 4.233 (4.211 0.022 4.356) (np: 33.8, max-t: 0.046) [wd: 1.15e-01] [lr: 2.20e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   250] grad_stats: [0.00e+00 0.00e+00] (1.14e+00, 3.97e+00)
INFO:root:[1,   260] loss: 4.216 (4.194 0.022 4.342) (np: 34.0, max-t: 0.047) [wd: 1.21e-01] [lr: 2.21e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   260] grad_stats: [0.00e+00 0.00e+00] (8.78e-01, 3.70e+00)
INFO:root:[1,   270] loss: 4.200 (4.177 0.023 4.328) (np: 34.3, max-t: 0.048) [wd: 1.26e-01] [lr: 2.22e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   270] grad_stats: [0.00e+00 0.00e+00] (1.10e+00, 4.19e+00)
INFO:root:[1,   280] loss: 4.186 (4.162 0.024 4.315) (np: 34.5, max-t: 0.049) [wd: 1.32e-01] [lr: 2.23e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   280] grad_stats: [0.00e+00 0.00e+00] (1.29e+00, 4.49e+00)
INFO:root:[1,   290] loss: 4.170 (4.146 0.024 4.302) (np: 34.7, max-t: 0.049) [wd: 1.38e-01] [lr: 2.23e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   290] grad_stats: [0.00e+00 0.00e+00] (9.71e-01, 3.39e+00)
INFO:root:[1,   300] loss: 4.156 (4.131 0.024 4.289) (np: 34.9, max-t: 0.050) [wd: 1.44e-01] [lr: 2.24e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   300] grad_stats: [0.00e+00 0.00e+00] (9.29e-01, 3.55e+00)
INFO:root:[1,   310] loss: 4.140 (4.115 0.025 4.275) (np: 35.1, max-t: 0.051) [wd: 1.50e-01] [lr: 2.25e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   310] grad_stats: [0.00e+00 0.00e+00] (8.91e-01, 3.16e+00)
INFO:root:[1,   320] loss: 4.125 (4.100 0.025 4.262) (np: 35.3, max-t: 0.052) [wd: 1.57e-01] [lr: 2.26e-04] [mem: 9.54e+02] (57 ms; 10 ms)
INFO:root:[1,   320] grad_stats: [0.00e+00 0.00e+00] (1.59e+00, 5.16e+00)
INFO:root:[1,   330] loss: 4.110 (4.085 0.025 4.249) (np: 35.4, max-t: 0.053) [wd: 1.63e-01] [lr: 2.27e-04] [mem: 9.54e+02] (56 ms; 10 ms)
INFO:root:[1,   330] grad_stats: [0.00e+00 0.00e+00] (1.34e+00, 4.57e+00)
INFO:root:[1,   340] loss: 4.097 (4.071 0.026 4.237) (np: 35.6, max-t: 0.054) [wd: 1.70e-01] [lr: 2.27e-04] [mem: 9.54e+02] (56 ms; 10 ms)
INFO:root:[1,   340] grad_stats: [0.00e+00 0.00e+00] (1.15e+00, 4.15e+00)
INFO:root:[1,   350] loss: 4.085 (4.058 0.027 4.225) (np: 35.7, max-t: 0.055) [wd: 1.76e-01] [lr: 2.28e-04] [mem: 1.23e+03] (56 ms; 10 ms)
INFO:root:[1,   350] grad_stats: [0.00e+00 0.00e+00] (1.39e+00, 4.76e+00)
INFO:root:[1,   360] loss: 4.072 (4.045 0.027 4.213) (np: 35.9, max-t: 0.056) [wd: 1.83e-01] [lr: 2.29e-04] [mem: 1.23e+03] (57 ms; 10 ms)
INFO:root:[1,   360] grad_stats: [0.00e+00 0.00e+00] (1.69e+00, 5.48e+00)
INFO:root:[1,   370] loss: 4.059 (4.031 0.028 4.201) (np: 36.0, max-t: 0.056) [wd: 1.90e-01] [lr: 2.30e-04] [mem: 1.23e+03] (56 ms; 10 ms)
INFO:root:[1,   370] grad_stats: [0.00e+00 0.00e+00] (1.47e+00, 5.42e+00)
INFO:root:[1,   380] loss: 4.048 (4.020 0.028 4.191) (np: 36.2, max-t: 0.057) [wd: 1.96e-01] [lr: 2.31e-04] [mem: 1.43e+03] (57 ms; 11 ms)
INFO:root:[1,   380] grad_stats: [0.00e+00 0.00e+00] (2.05e+00, 7.17e+00)
INFO:root:[1,   390] loss: 4.038 (4.009 0.029 4.181) (np: 36.2, max-t: 0.058) [wd: 2.03e-01] [lr: 2.31e-04] [mem: 1.43e+03] (57 ms; 10 ms)
INFO:root:[1,   390] grad_stats: [0.00e+00 0.00e+00] (1.40e+00, 4.81e+00)
INFO:root:[1,   400] loss: 4.028 (3.997 0.030 4.171) (np: 36.4, max-t: 0.059) [wd: 2.10e-01] [lr: 2.32e-04] [mem: 1.43e+03] (57 ms; 10 ms)
INFO:root:[1,   400] grad_stats: [0.00e+00 0.00e+00] (2.15e+00, 7.17e+00)
INFO:root:[1,   410] loss: 4.016 (3.985 0.031 4.161) (np: 36.6, max-t: 0.060) [wd: 2.17e-01] [lr: 2.33e-04] [mem: 1.43e+03] (57 ms; 10 ms)
INFO:root:[1,   410] grad_stats: [0.00e+00 0.00e+00] (9.49e-01, 3.55e+00)
INFO:root:[1,   420] loss: 4.006 (3.975 0.031 4.151) (np: 36.7, max-t: 0.061) [wd: 2.23e-01] [lr: 2.34e-04] [mem: 1.43e+03] (57 ms; 10 ms)
INFO:root:[1,   420] grad_stats: [0.00e+00 0.00e+00] (1.39e+00, 4.81e+00)
INFO:root:[1,   430] loss: 3.995 (3.963 0.032 4.142) (np: 36.8, max-t: 0.062) [wd: 2.30e-01] [lr: 2.35e-04] [mem: 1.43e+03] (57 ms; 10 ms)
INFO:root:[1,   430] grad_stats: [0.00e+00 0.00e+00] (1.06e+00, 3.65e+00)
INFO:root:[1,   440] loss: 3.984 (3.952 0.032 4.132) (np: 37.0, max-t: 0.063) [wd: 2.37e-01] [lr: 2.35e-04] [mem: 1.43e+03] (57 ms; 10 ms)
INFO:root:[1,   440] grad_stats: [0.00e+00 0.00e+00] (1.30e+00, 4.47e+00)
INFO:root:[1,   450] loss: 3.975 (3.942 0.033 4.123) (np: 37.0, max-t: 0.063) [wd: 2.44e-01] [lr: 2.36e-04] [mem: 1.43e+03] (58 ms; 11 ms)
INFO:root:[1,   450] grad_stats: [0.00e+00 0.00e+00] (1.96e+00, 6.68e+00)
INFO:root:[1,   460] loss: 3.965 (3.931 0.034 4.113) (np: 37.2, max-t: 0.064) [wd: 2.50e-01] [lr: 2.37e-04] [mem: 1.43e+03] (58 ms; 11 ms)
INFO:root:[1,   460] grad_stats: [0.00e+00 0.00e+00] (1.82e+00, 6.20e+00)
INFO:root:[1,   470] loss: 3.955 (3.921 0.034 4.104) (np: 37.4, max-t: 0.065) [wd: 2.57e-01] [lr: 2.38e-04] [mem: 1.43e+03] (58 ms; 11 ms)
INFO:root:[1,   470] grad_stats: [0.00e+00 0.00e+00] (2.93e+00, 1.03e+01)
INFO:root:[1,   480] loss: 3.947 (3.911 0.035 4.096) (np: 37.5, max-t: 0.066) [wd: 2.64e-01] [lr: 2.39e-04] [mem: 1.43e+03] (58 ms; 11 ms)
INFO:root:[1,   480] grad_stats: [0.00e+00 0.00e+00] (2.43e+00, 8.45e+00)
INFO:root:[1,   490] loss: 3.938 (3.902 0.036 4.087) (np: 37.6, max-t: 0.067) [wd: 2.70e-01] [lr: 2.39e-04] [mem: 1.60e+03] (58 ms; 11 ms)
INFO:root:[1,   490] grad_stats: [0.00e+00 0.00e+00] (2.58e+00, 9.11e+00)
INFO:root:[1,   500] loss: 3.928 (3.892 0.036 4.078) (np: 37.8, max-t: 0.068) [wd: 2.77e-01] [lr: 2.40e-04] [mem: 1.60e+03] (58 ms; 11 ms)
INFO:root:[1,   500] grad_stats: [0.00e+00 0.00e+00] (1.46e+00, 5.10e+00)
INFO:root:[1,   510] loss: 3.920 (3.883 0.037 4.070) (np: 37.9, max-t: 0.069) [wd: 2.83e-01] [lr: 2.41e-04] [mem: 1.60e+03] (58 ms; 11 ms)
INFO:root:[1,   510] grad_stats: [0.00e+00 0.00e+00] (1.56e+00, 5.35e+00)
INFO:root:[1,   520] loss: 3.911 (3.874 0.037 4.062) (np: 38.0, max-t: 0.069) [wd: 2.90e-01] [lr: 2.42e-04] [mem: 1.60e+03] (58 ms; 11 ms)
INFO:root:[1,   520] grad_stats: [0.00e+00 0.00e+00] (1.49e+00, 5.20e+00)
INFO:root:[1,   530] loss: 3.903 (3.866 0.038 4.055) (np: 38.1, max-t: 0.070) [wd: 2.96e-01] [lr: 2.43e-04] [mem: 1.60e+03] (58 ms; 11 ms)
INFO:root:[1,   530] grad_stats: [0.00e+00 0.00e+00] (1.69e+00, 6.10e+00)
INFO:root:[1,   540] loss: 3.895 (3.857 0.038 4.047) (np: 38.2, max-t: 0.071) [wd: 3.02e-01] [lr: 2.43e-04] [mem: 1.60e+03] (58 ms; 11 ms)
INFO:root:[1,   540] grad_stats: [0.00e+00 0.00e+00] (1.72e+00, 6.27e+00)
INFO:root:[1,   550] loss: 3.887 (3.848 0.038 4.039) (np: 38.3, max-t: 0.072) [wd: 3.08e-01] [lr: 2.44e-04] [mem: 1.60e+03] (58 ms; 11 ms)
INFO:root:[1,   550] grad_stats: [0.00e+00 0.00e+00] (1.87e+00, 6.87e+00)
INFO:root:[1,   560] loss: 3.879 (3.839 0.039 4.032) (np: 38.4, max-t: 0.073) [wd: 3.14e-01] [lr: 2.45e-04] [mem: 1.60e+03] (58 ms; 11 ms)
INFO:root:[1,   560] grad_stats: [0.00e+00 0.00e+00] (2.37e+00, 8.55e+00)
/ext3/medfuse/lib/python3.6/site-packages/torch/nn/modules/rnn.py:683: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448272031/work/aten/src/ATen/native/cudnn/RNN.cpp:924.)
  self.num_layers, self.dropout, self.training, self.bidirectional)
--- Logging error ---
Traceback (most recent call last):
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 82, in write
    category_id = self._possible_values[channel].index(value)
ValueError: '5 O' is not in list

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 994, in emit
    msg = self.format(record)
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 840, in format
    return fmt.format(record)
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 577, in format
    record.message = record.getMessage()
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 338, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/ext3/medfuse/lib/python3.6/multiprocessing/spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "/ext3/medfuse/lib/python3.6/multiprocessing/spawn.py", line 118, in _main
    return self._bootstrap()
  File "/ext3/medfuse/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/ext3/medfuse/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/main.py", line 69, in process_main
    return msn(params, medfuse_args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/msn_train.py", line 336, in main
    for itr, data in enumerate(unsupervised_loader):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_dataset.py", line 98, in __getitem__
    data[i] = self.discretizer.transform(data[i], end=ts)[0]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 113, in transform
    write(data, bin_id, channel, row[j], begin_pos)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 84, in write
    logger.info(channel, value)
Message: 'Glascow coma scale verbal response'
Arguments: ('5 O',)
--- Logging error ---
Traceback (most recent call last):
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 113, in transform
    write(data, bin_id, channel, row[j], begin_pos)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 88, in write
    one_hot[category_id] = 1
UnboundLocalError: local variable 'category_id' referenced before assignment

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 994, in emit
    msg = self.format(record)
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 840, in format
    return fmt.format(record)
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 577, in format
    record.message = record.getMessage()
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 338, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/ext3/medfuse/lib/python3.6/multiprocessing/spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "/ext3/medfuse/lib/python3.6/multiprocessing/spawn.py", line 118, in _main
    return self._bootstrap()
  File "/ext3/medfuse/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/ext3/medfuse/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/main.py", line 69, in process_main
    return msn(params, medfuse_args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/msn_train.py", line 336, in main
    for itr, data in enumerate(unsupervised_loader):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_dataset.py", line 98, in __getitem__
    data[i] = self.discretizer.transform(data[i], end=ts)[0]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 115, in transform
    logger.info(channel, row[j])
Message: 'Glascow coma scale verbal response'
Arguments: ('5 O',)
--- Logging error ---
Traceback (most recent call last):
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 82, in write
    category_id = self._possible_values[channel].index(value)
ValueError: '5 O' is not in list

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 994, in emit
    msg = self.format(record)
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 840, in format
    return fmt.format(record)
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 577, in format
    record.message = record.getMessage()
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 338, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/ext3/medfuse/lib/python3.6/multiprocessing/spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "/ext3/medfuse/lib/python3.6/multiprocessing/spawn.py", line 118, in _main
    return self._bootstrap()
  File "/ext3/medfuse/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/ext3/medfuse/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/main.py", line 69, in process_main
    return msn(params, medfuse_args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/msn_train.py", line 336, in main
    for itr, data in enumerate(unsupervised_loader):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_dataset.py", line 98, in __getitem__
    data[i] = self.discretizer.transform(data[i], end=ts)[0]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 138, in transform
    write(data, bin_id, channel, imputed_value, begin_pos)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 84, in write
    logger.info(channel, value)
Message: 'Glascow coma scale verbal response'
Arguments: ('5 O',)
Traceback (most recent call last):
  File "main.py", line 84, in <module>
    args=(args.fname, num_gpus, args.devices, args.modality, args))
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/main.py", line 69, in process_main
    return msn(params, medfuse_args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/msn_train.py", line 336, in main
    for itr, data in enumerate(unsupervised_loader):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_dataset.py", line 98, in __getitem__
    data[i] = self.discretizer.transform(data[i], end=ts)[0]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 138, in transform
    write(data, bin_id, channel, imputed_value, begin_pos)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 88, in write
    one_hot[category_id] = 1
UnboundLocalError: local variable 'category_id' referenced before assignment

