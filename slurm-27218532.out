INFO:root:called-params configs/pretrain/msn_ehr_lstm.yaml
INFO:root:loaded params...
{   'criterion': {   'batch_size': 64,
                     'ent_weight': 0.0,
                     'final_sharpen': 0.25,
                     'me_max': True,
                     'memax_weight': 1.0,
                     'num_proto': 128,
                     'start_sharpen': 0.25,
                     'temperature': 0.1,
                     'use_ent': True,
                     'use_sinkhorn': True},
    'data': {   'color_jitter_strength': 0.5,
                'focal_size': 96,
                'focal_views': 10,
                'image_folder': '/imagenet/',
                'label_smoothing': 0.0,
                'modality': 'ehr',
                'num_workers': 10,
                'patch_drop': 0.15,
                'pin_mem': True,
                'rand_size': 224,
                'rand_views': 1,
                'root_path': '.'},
    'logging': {   'folder': 'checkpoint/msn_ehr_logs/',
                   'write_tag': 'msn-experiment-1'},
    'meta': {   'bottleneck': 1,
                'copy_data': False,
                'drop_path_rate': 0.0,
                'hidden_dim': 1024,
                'load_checkpoint': False,
                'model_name': 'deit_small',
                'output_dim': 128,
                'read_checkpoint': None,
                'use_bn': True,
                'use_fp16': False,
                'use_pred_head': False},
    'optimization': {   'clip_grad': 3.0,
                        'epochs': 100,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'lr': 0.001,
                        'start_lr': 0.0002,
                        'warmup': 15,
                        'weight_decay': 0.04}}
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for 1 nodes.
INFO:root:Running... (rank: 0/1)
INFO:root:Running ehr
INFO:root:LSTM(
  (layer0): LSTM(76, 128, batch_first=True)
  (dense_layer): Linear(in_features=128, out_features=128, bias=True)
  (fc): Sequential(
    (fc1): Linear(in_features=128, out_features=1024, bias=True)
    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gelu1): GELU()
    (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gelu2): GELU()
    (fc3): Linear(in_features=1024, out_features=128, bias=True)
  )
)
INFO:root:making data transforms
INFO:root:{'criterion': {'ent_weight': 0.0, 'final_sharpen': 0.25, 'me_max': True, 'memax_weight': 1.0, 'num_proto': 128, 'start_sharpen': 0.25, 'temperature': 0.1, 'batch_size': 64, 'use_ent': True, 'use_sinkhorn': True}, 'data': {'modality': 'ehr', 'color_jitter_strength': 0.5, 'pin_mem': True, 'num_workers': 10, 'image_folder': '/imagenet/', 'label_smoothing': 0.0, 'patch_drop': 0.15, 'rand_size': 224, 'focal_size': 96, 'rand_views': 1, 'focal_views': 10, 'root_path': '.'}, 'logging': {'folder': 'checkpoint/msn_ehr_logs/', 'write_tag': 'msn-experiment-1'}, 'meta': {'bottleneck': 1, 'copy_data': False, 'drop_path_rate': 0.0, 'hidden_dim': 1024, 'load_checkpoint': False, 'model_name': 'deit_small', 'output_dim': 128, 'read_checkpoint': None, 'use_bn': True, 'use_fp16': False, 'use_pred_head': False}, 'optimization': {'clip_grad': 3.0, 'epochs': 100, 'final_lr': 1e-06, 'final_weight_decay': 0.4, 'lr': 0.001, 'start_lr': 0.0002, 'warmup': 15, 'weight_decay': 0.04}}
INFO:root:MIMICCXR ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, devices=['cuda:0'], dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='configs/pretrain/msn_ehr_lstm.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, modality='ehr', mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:iterations per epoch: 666
INFO:root:Created prototypes: torch.Size([128, 128])
INFO:root:Requires grad: True
INFO:root:Using AdamW
INFO:root:Epoch 1
INFO:root:[1,     0] loss: 5.289 (5.001 0.288 4.533) (np: 30.0, max-t: 0.030) [wd: 4.00e-02] [lr: 2.00e-04] [mem: 4.17e+02] (210 ms; 19 ms)
INFO:root:[1,     0] grad_stats: [0.00e+00 0.00e+00] (9.59e-01, 6.75e+00)
INFO:root:[1,    10] loss: 4.896 (4.798 0.098 4.710) (np: 26.2, max-t: 0.031) [wd: 4.00e-02] [lr: 2.01e-04] [mem: 6.79e+02] (55 ms; 20 ms)
INFO:root:[1,    10] grad_stats: [0.00e+00 0.00e+00] (1.77e-01, 1.30e+00)
INFO:root:[1,    20] loss: 4.781 (4.723 0.058 4.726) (np: 27.0, max-t: 0.031) [wd: 4.00e-02] [lr: 2.02e-04] [mem: 6.99e+02] (48 ms; 20 ms)
INFO:root:[1,    20] grad_stats: [0.00e+00 0.00e+00] (1.52e-01, 9.54e-01)
INFO:root:[1,    30] loss: 4.722 (4.680 0.042 4.715) (np: 27.8, max-t: 0.032) [wd: 4.00e-02] [lr: 2.02e-04] [mem: 6.99e+02] (46 ms; 20 ms)
INFO:root:[1,    30] grad_stats: [0.00e+00 0.00e+00] (3.27e-01, 1.26e+00)
INFO:root:[1,    40] loss: 4.676 (4.642 0.034 4.692) (np: 27.7, max-t: 0.033) [wd: 4.00e-02] [lr: 2.03e-04] [mem: 6.99e+02] (43 ms; 19 ms)
INFO:root:[1,    40] grad_stats: [0.00e+00 0.00e+00] (6.07e-01, 2.04e+00)
INFO:root:[1,    50] loss: 4.639 (4.610 0.029 4.669) (np: 28.4, max-t: 0.033) [wd: 4.00e-02] [lr: 2.04e-04] [mem: 1.06e+03] (43 ms; 20 ms)
INFO:root:[1,    50] grad_stats: [0.00e+00 0.00e+00] (4.84e-01, 1.89e+00)
INFO:root:[1,    60] loss: 4.608 (4.582 0.025 4.650) (np: 28.8, max-t: 0.034) [wd: 4.00e-02] [lr: 2.05e-04] [mem: 1.06e+03] (44 ms; 21 ms)
INFO:root:[1,    60] grad_stats: [0.00e+00 0.00e+00] (2.83e-01, 1.38e+00)
INFO:root:[1,    70] loss: 4.581 (4.558 0.024 4.630) (np: 29.0, max-t: 0.035) [wd: 4.00e-02] [lr: 2.06e-04] [mem: 1.06e+03] (43 ms; 21 ms)
INFO:root:[1,    70] grad_stats: [0.00e+00 0.00e+00] (6.72e-01, 2.74e+00)
INFO:root:[1,    80] loss: 4.556 (4.534 0.022 4.613) (np: 29.2, max-t: 0.035) [wd: 4.00e-02] [lr: 2.06e-04] [mem: 1.06e+03] (43 ms; 21 ms)
INFO:root:[1,    80] grad_stats: [0.00e+00 0.00e+00] (5.96e-01, 2.70e+00)
INFO:root:[1,    90] loss: 4.532 (4.511 0.021 4.597) (np: 29.6, max-t: 0.036) [wd: 4.00e-02] [lr: 2.07e-04] [mem: 1.06e+03] (43 ms; 21 ms)
INFO:root:[1,    90] grad_stats: [0.00e+00 0.00e+00] (4.05e-01, 1.63e+00)
INFO:root:[1,   100] loss: 4.509 (4.489 0.021 4.581) (np: 29.9, max-t: 0.036) [wd: 4.00e-02] [lr: 2.08e-04] [mem: 1.06e+03] (42 ms; 21 ms)
INFO:root:[1,   100] grad_stats: [0.00e+00 0.00e+00] (3.75e-01, 1.79e+00)
INFO:root:[1,   110] loss: 4.486 (4.466 0.020 4.563) (np: 30.2, max-t: 0.037) [wd: 4.00e-02] [lr: 2.09e-04] [mem: 1.28e+03] (43 ms; 21 ms)
INFO:root:[1,   110] grad_stats: [0.00e+00 0.00e+00] (7.13e-01, 2.70e+00)
INFO:root:[1,   120] loss: 4.463 (4.443 0.019 4.547) (np: 30.6, max-t: 0.038) [wd: 4.00e-02] [lr: 2.10e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   120] grad_stats: [0.00e+00 0.00e+00] (4.46e-01, 2.00e+00)
INFO:root:[1,   130] loss: 4.442 (4.422 0.019 4.529) (np: 30.9, max-t: 0.039) [wd: 4.00e-02] [lr: 2.10e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   130] grad_stats: [0.00e+00 0.00e+00] (5.82e-01, 2.56e+00)
INFO:root:[1,   140] loss: 4.420 (4.401 0.020 4.513) (np: 31.2, max-t: 0.039) [wd: 4.00e-02] [lr: 2.11e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   140] grad_stats: [0.00e+00 0.00e+00] (7.34e-01, 2.53e+00)
INFO:root:[1,   150] loss: 4.398 (4.379 0.019 4.496) (np: 31.6, max-t: 0.040) [wd: 4.00e-02] [lr: 2.12e-04] [mem: 1.28e+03] (43 ms; 21 ms)
INFO:root:[1,   150] grad_stats: [0.00e+00 0.00e+00] (7.57e-01, 3.23e+00)
INFO:root:[1,   160] loss: 4.375 (4.356 0.019 4.479) (np: 31.9, max-t: 0.041) [wd: 4.00e-02] [lr: 2.13e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   160] grad_stats: [0.00e+00 0.00e+00] (5.01e-01, 2.08e+00)
INFO:root:[1,   170] loss: 4.358 (4.338 0.020 4.461) (np: 32.1, max-t: 0.041) [wd: 4.00e-02] [lr: 2.14e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   170] grad_stats: [0.00e+00 0.00e+00] (1.18e+00, 4.52e+00)
INFO:root:[1,   180] loss: 4.336 (4.316 0.021 4.445) (np: 32.4, max-t: 0.042) [wd: 4.00e-02] [lr: 2.14e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   180] grad_stats: [0.00e+00 0.00e+00] (5.03e-01, 2.34e+00)
INFO:root:[1,   190] loss: 4.317 (4.296 0.021 4.428) (np: 32.7, max-t: 0.043) [wd: 4.00e-02] [lr: 2.15e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   190] grad_stats: [0.00e+00 0.00e+00] (5.65e-01, 2.60e+00)
INFO:root:[1,   200] loss: 4.297 (4.275 0.022 4.412) (np: 33.0, max-t: 0.044) [wd: 4.00e-02] [lr: 2.16e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   200] grad_stats: [0.00e+00 0.00e+00] (6.27e-01, 2.67e+00)
INFO:root:[1,   210] loss: 4.279 (4.256 0.022 4.397) (np: 33.3, max-t: 0.045) [wd: 4.00e-02] [lr: 2.17e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   210] grad_stats: [0.00e+00 0.00e+00] (1.06e+00, 4.48e+00)
INFO:root:[1,   220] loss: 4.259 (4.236 0.022 4.380) (np: 33.6, max-t: 0.046) [wd: 4.00e-02] [lr: 2.18e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   220] grad_stats: [0.00e+00 0.00e+00] (8.80e-01, 3.50e+00)
INFO:root:[1,   230] loss: 4.238 (4.216 0.023 4.364) (np: 33.8, max-t: 0.047) [wd: 4.00e-02] [lr: 2.18e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   230] grad_stats: [0.00e+00 0.00e+00] (6.75e-01, 3.23e+00)
INFO:root:[1,   240] loss: 4.219 (4.196 0.023 4.348) (np: 34.0, max-t: 0.048) [wd: 4.00e-02] [lr: 2.19e-04] [mem: 1.28e+03] (41 ms; 21 ms)
INFO:root:[1,   240] grad_stats: [0.00e+00 0.00e+00] (6.55e-01, 2.61e+00)
INFO:root:[1,   250] loss: 4.200 (4.177 0.023 4.333) (np: 34.3, max-t: 0.049) [wd: 4.00e-02] [lr: 2.20e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   250] grad_stats: [0.00e+00 0.00e+00] (1.02e+00, 4.04e+00)
INFO:root:[1,   260] loss: 4.183 (4.159 0.024 4.318) (np: 34.5, max-t: 0.050) [wd: 4.00e-02] [lr: 2.21e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   260] grad_stats: [0.00e+00 0.00e+00] (1.12e+00, 3.80e+00)
INFO:root:[1,   270] loss: 4.165 (4.141 0.024 4.303) (np: 34.8, max-t: 0.051) [wd: 4.00e-02] [lr: 2.22e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   270] grad_stats: [0.00e+00 0.00e+00] (1.08e+00, 3.47e+00)
INFO:root:[1,   280] loss: 4.148 (4.123 0.025 4.289) (np: 35.0, max-t: 0.052) [wd: 4.00e-02] [lr: 2.23e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   280] grad_stats: [0.00e+00 0.00e+00] (1.16e+00, 4.10e+00)
INFO:root:[1,   290] loss: 4.133 (4.108 0.025 4.276) (np: 35.2, max-t: 0.053) [wd: 4.00e-02] [lr: 2.23e-04] [mem: 1.28e+03] (42 ms; 21 ms)
INFO:root:[1,   290] grad_stats: [0.00e+00 0.00e+00] (8.55e-01, 3.45e+00)
INFO:root:[1,   300] loss: 4.118 (4.092 0.026 4.262) (np: 35.4, max-t: 0.054) [wd: 4.00e-02] [lr: 2.24e-04] [mem: 1.60e+03] (42 ms; 21 ms)
INFO:root:[1,   300] grad_stats: [0.00e+00 0.00e+00] (1.52e+00, 4.92e+00)
INFO:root:[1,   310] loss: 4.103 (4.076 0.027 4.249) (np: 35.6, max-t: 0.055) [wd: 4.00e-02] [lr: 2.25e-04] [mem: 1.60e+03] (42 ms; 21 ms)
INFO:root:[1,   310] grad_stats: [0.00e+00 0.00e+00] (1.83e+00, 6.04e+00)
INFO:root:[1,   320] loss: 4.088 (4.060 0.028 4.235) (np: 35.7, max-t: 0.056) [wd: 4.00e-02] [lr: 2.26e-04] [mem: 1.60e+03] (42 ms; 21 ms)
INFO:root:[1,   320] grad_stats: [0.00e+00 0.00e+00] (1.24e+00, 4.24e+00)
INFO:root:[1,   330] loss: 4.073 (4.045 0.028 4.222) (np: 36.0, max-t: 0.057) [wd: 4.00e-02] [lr: 2.27e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[1,   330] grad_stats: [0.00e+00 0.00e+00] (1.02e+00, 3.83e+00)
INFO:root:[1,   340] loss: 4.059 (4.030 0.029 4.210) (np: 36.1, max-t: 0.059) [wd: 4.00e-02] [lr: 2.27e-04] [mem: 1.60e+03] (42 ms; 21 ms)
INFO:root:[1,   340] grad_stats: [0.00e+00 0.00e+00] (1.79e+00, 6.12e+00)
INFO:root:[1,   350] loss: 4.045 (4.015 0.030 4.197) (np: 36.3, max-t: 0.060) [wd: 4.00e-02] [lr: 2.28e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[1,   350] grad_stats: [0.00e+00 0.00e+00] (1.91e+00, 6.30e+00)
INFO:root:[1,   360] loss: 4.031 (4.001 0.030 4.185) (np: 36.5, max-t: 0.061) [wd: 4.00e-02] [lr: 2.29e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[1,   360] grad_stats: [0.00e+00 0.00e+00] (9.38e-01, 3.65e+00)
INFO:root:[1,   370] loss: 4.017 (3.987 0.031 4.173) (np: 36.7, max-t: 0.062) [wd: 4.00e-02] [lr: 2.30e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[1,   370] grad_stats: [0.00e+00 0.00e+00] (1.51e+00, 4.89e+00)
INFO:root:[1,   380] loss: 4.004 (3.973 0.031 4.161) (np: 36.8, max-t: 0.064) [wd: 4.00e-02] [lr: 2.31e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[1,   380] grad_stats: [0.00e+00 0.00e+00] (1.94e+00, 6.72e+00)
INFO:root:[1,   390] loss: 3.991 (3.959 0.031 4.150) (np: 37.0, max-t: 0.065) [wd: 4.00e-02] [lr: 2.31e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[1,   390] grad_stats: [0.00e+00 0.00e+00] (1.83e+00, 6.38e+00)
INFO:root:[1,   400] loss: 3.979 (3.947 0.032 4.139) (np: 37.2, max-t: 0.066) [wd: 4.00e-02] [lr: 2.32e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[1,   400] grad_stats: [0.00e+00 0.00e+00] (2.27e+00, 8.10e+00)
INFO:root:[1,   410] loss: 3.966 (3.933 0.032 4.129) (np: 37.3, max-t: 0.067) [wd: 4.00e-02] [lr: 2.33e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   410] grad_stats: [0.00e+00 0.00e+00] (1.33e+00, 4.65e+00)
INFO:root:[1,   420] loss: 3.955 (3.921 0.033 4.119) (np: 37.5, max-t: 0.068) [wd: 4.00e-02] [lr: 2.34e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   420] grad_stats: [0.00e+00 0.00e+00] (1.31e+00, 4.57e+00)
INFO:root:[1,   430] loss: 3.942 (3.909 0.033 4.108) (np: 37.7, max-t: 0.070) [wd: 4.00e-02] [lr: 2.35e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   430] grad_stats: [0.00e+00 0.00e+00] (2.15e+00, 7.62e+00)
INFO:root:[1,   440] loss: 3.931 (3.897 0.034 4.098) (np: 37.9, max-t: 0.071) [wd: 4.00e-02] [lr: 2.35e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   440] grad_stats: [0.00e+00 0.00e+00] (3.75e+00, 1.34e+01)
INFO:root:[1,   450] loss: 3.919 (3.884 0.035 4.088) (np: 38.0, max-t: 0.072) [wd: 4.00e-02] [lr: 2.36e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   450] grad_stats: [0.00e+00 0.00e+00] (2.93e+00, 9.94e+00)
INFO:root:[1,   460] loss: 3.908 (3.872 0.036 4.078) (np: 38.2, max-t: 0.074) [wd: 4.00e-02] [lr: 2.37e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   460] grad_stats: [0.00e+00 0.00e+00] (4.65e+00, 1.69e+01)
INFO:root:[1,   470] loss: 3.898 (3.861 0.037 4.069) (np: 38.4, max-t: 0.075) [wd: 4.00e-02] [lr: 2.38e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   470] grad_stats: [0.00e+00 0.00e+00] (2.60e+00, 9.37e+00)
INFO:root:[1,   480] loss: 3.888 (3.850 0.038 4.059) (np: 38.6, max-t: 0.076) [wd: 4.00e-02] [lr: 2.39e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   480] grad_stats: [0.00e+00 0.00e+00] (2.87e+00, 9.97e+00)
INFO:root:[1,   490] loss: 3.877 (3.838 0.039 4.050) (np: 38.7, max-t: 0.078) [wd: 4.00e-02] [lr: 2.39e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   490] grad_stats: [0.00e+00 0.00e+00] (2.55e+00, 9.15e+00)
INFO:root:[1,   500] loss: 3.867 (3.828 0.039 4.041) (np: 38.9, max-t: 0.079) [wd: 4.00e-02] [lr: 2.40e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   500] grad_stats: [0.00e+00 0.00e+00] (3.20e+00, 1.15e+01)
INFO:root:[1,   510] loss: 3.856 (3.816 0.040 4.032) (np: 39.1, max-t: 0.080) [wd: 4.00e-02] [lr: 2.41e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   510] grad_stats: [0.00e+00 0.00e+00] (3.07e+00, 1.11e+01)
INFO:root:[1,   520] loss: 3.847 (3.806 0.040 4.024) (np: 39.2, max-t: 0.082) [wd: 4.00e-02] [lr: 2.42e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   520] grad_stats: [0.00e+00 0.00e+00] (4.19e+00, 1.52e+01)
INFO:root:[1,   530] loss: 3.837 (3.796 0.041 4.015) (np: 39.4, max-t: 0.083) [wd: 4.00e-02] [lr: 2.43e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   530] grad_stats: [0.00e+00 0.00e+00] (2.54e+00, 9.57e+00)
INFO:root:[1,   540] loss: 3.827 (3.786 0.041 4.006) (np: 39.5, max-t: 0.084) [wd: 4.00e-02] [lr: 2.43e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   540] grad_stats: [0.00e+00 0.00e+00] (2.75e+00, 9.88e+00)
INFO:root:[1,   550] loss: 3.817 (3.775 0.042 3.997) (np: 39.7, max-t: 0.085) [wd: 4.00e-02] [lr: 2.44e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   550] grad_stats: [0.00e+00 0.00e+00] (2.12e+00, 7.95e+00)
INFO:root:[1,   560] loss: 3.807 (3.764 0.043 3.989) (np: 39.8, max-t: 0.087) [wd: 4.00e-02] [lr: 2.45e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   560] grad_stats: [0.00e+00 0.00e+00] (3.23e+00, 1.18e+01)
INFO:root:[1,   570] loss: 3.797 (3.753 0.044 3.980) (np: 40.0, max-t: 0.088) [wd: 4.00e-02] [lr: 2.46e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   570] grad_stats: [0.00e+00 0.00e+00] (5.74e+00, 2.18e+01)
INFO:root:[1,   580] loss: 3.787 (3.743 0.045 3.972) (np: 40.1, max-t: 0.090) [wd: 4.00e-02] [lr: 2.47e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   580] grad_stats: [0.00e+00 0.00e+00] (2.54e+00, 9.68e+00)
INFO:root:[1,   590] loss: 3.778 (3.733 0.045 3.964) (np: 40.2, max-t: 0.091) [wd: 4.00e-02] [lr: 2.47e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   590] grad_stats: [0.00e+00 0.00e+00] (3.62e+00, 1.38e+01)
INFO:root:[1,   600] loss: 3.769 (3.724 0.046 3.956) (np: 40.4, max-t: 0.092) [wd: 4.00e-02] [lr: 2.48e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   600] grad_stats: [0.00e+00 0.00e+00] (2.49e+00, 9.09e+00)
INFO:root:[1,   610] loss: 3.759 (3.713 0.046 3.948) (np: 40.6, max-t: 0.094) [wd: 4.00e-02] [lr: 2.49e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   610] grad_stats: [0.00e+00 0.00e+00] (2.29e+00, 8.76e+00)
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:[1,   620] loss: 3.749 (3.703 0.047 3.940) (np: 40.7, max-t: 0.095) [wd: 4.00e-02] [lr: 2.50e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   620] grad_stats: [0.00e+00 0.00e+00] (3.46e+00, 1.30e+01)
INFO:root:[1,   630] loss: 3.739 (3.692 0.047 3.932) (np: 40.9, max-t: 0.097) [wd: 4.01e-02] [lr: 2.51e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   630] grad_stats: [0.00e+00 0.00e+00] (3.19e+00, 1.20e+01)
INFO:root:[1,   640] loss: 3.730 (3.682 0.048 3.924) (np: 41.0, max-t: 0.098) [wd: 4.01e-02] [lr: 2.51e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   640] grad_stats: [0.00e+00 0.00e+00] (3.96e+00, 1.50e+01)
INFO:root:[1,   650] loss: 3.721 (3.672 0.048 3.916) (np: 41.2, max-t: 0.100) [wd: 4.01e-02] [lr: 2.52e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   650] grad_stats: [0.00e+00 0.00e+00] (7.25e+00, 2.84e+01)
INFO:root:[1,   660] loss: 3.713 (3.664 0.049 3.909) (np: 41.3, max-t: 0.101) [wd: 4.01e-02] [lr: 2.53e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[1,   660] grad_stats: [0.00e+00 0.00e+00] (4.46e+00, 1.70e+01)
INFO:root:avg. loss 3.709
INFO:root:Epoch 2
INFO:root:[2,     0] loss: 3.194 (3.121 0.073 3.472) (np: 52.0, max-t: 0.172) [wd: 4.01e-02] [lr: 2.53e-04] [mem: 1.60e+03] (38 ms; 19 ms)
INFO:root:[2,     0] grad_stats: [0.00e+00 0.00e+00] (3.78e+00, 1.42e+01)
INFO:root:[2,    10] loss: 3.098 (3.022 0.076 3.403) (np: 50.9, max-t: 0.192) [wd: 4.01e-02] [lr: 2.54e-04] [mem: 1.60e+03] (40 ms; 20 ms)
INFO:root:[2,    10] grad_stats: [0.00e+00 0.00e+00] (4.59e+00, 1.80e+01)
INFO:root:[2,    20] loss: 3.096 (3.022 0.074 3.401) (np: 51.4, max-t: 0.195) [wd: 4.01e-02] [lr: 2.55e-04] [mem: 1.60e+03] (40 ms; 20 ms)
INFO:root:[2,    20] grad_stats: [0.00e+00 0.00e+00] (4.45e+00, 1.80e+01)
INFO:root:[2,    30] loss: 3.068 (2.985 0.082 3.377) (np: 52.0, max-t: 0.205) [wd: 4.01e-02] [lr: 2.56e-04] [mem: 1.60e+03] (40 ms; 20 ms)
INFO:root:[2,    30] grad_stats: [0.00e+00 0.00e+00] (4.21e+00, 1.62e+01)
INFO:root:[2,    40] loss: 3.072 (2.984 0.087 3.365) (np: 51.9, max-t: 0.209) [wd: 4.01e-02] [lr: 2.57e-04] [mem: 1.60e+03] (39 ms; 19 ms)
INFO:root:[2,    40] grad_stats: [0.00e+00 0.00e+00] (6.30e+00, 2.50e+01)
INFO:root:[2,    50] loss: 3.066 (2.978 0.088 3.359) (np: 51.7, max-t: 0.210) [wd: 4.01e-02] [lr: 2.57e-04] [mem: 1.60e+03] (40 ms; 20 ms)
INFO:root:[2,    50] grad_stats: [0.00e+00 0.00e+00] (4.44e+00, 1.81e+01)
INFO:root:[2,    60] loss: 3.052 (2.965 0.087 3.353) (np: 51.8, max-t: 0.211) [wd: 4.01e-02] [lr: 2.58e-04] [mem: 1.60e+03] (42 ms; 21 ms)
INFO:root:[2,    60] grad_stats: [0.00e+00 0.00e+00] (5.12e+00, 2.00e+01)
INFO:root:[2,    70] loss: 3.052 (2.964 0.088 3.352) (np: 51.7, max-t: 0.211) [wd: 4.01e-02] [lr: 2.59e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,    70] grad_stats: [0.00e+00 0.00e+00] (7.59e+00, 3.00e+01)
INFO:root:[2,    80] loss: 3.051 (2.961 0.090 3.346) (np: 51.7, max-t: 0.213) [wd: 4.01e-02] [lr: 2.60e-04] [mem: 1.60e+03] (40 ms; 21 ms)
INFO:root:[2,    80] grad_stats: [0.00e+00 0.00e+00] (8.45e+00, 3.38e+01)
INFO:root:[2,    90] loss: 3.043 (2.950 0.093 3.337) (np: 51.8, max-t: 0.216) [wd: 4.01e-02] [lr: 2.61e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,    90] grad_stats: [0.00e+00 0.00e+00] (4.53e+00, 1.86e+01)
INFO:root:[2,   100] loss: 3.036 (2.942 0.095 3.332) (np: 51.9, max-t: 0.219) [wd: 4.01e-02] [lr: 2.61e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   100] grad_stats: [0.00e+00 0.00e+00] (5.96e+00, 2.43e+01)
INFO:root:[2,   110] loss: 3.030 (2.933 0.097 3.324) (np: 52.0, max-t: 0.221) [wd: 4.01e-02] [lr: 2.62e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   110] grad_stats: [0.00e+00 0.00e+00] (5.33e+00, 2.17e+01)
INFO:root:[2,   120] loss: 3.021 (2.925 0.096 3.318) (np: 52.1, max-t: 0.222) [wd: 4.01e-02] [lr: 2.63e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   120] grad_stats: [0.00e+00 0.00e+00] (7.06e+00, 2.88e+01)
INFO:root:[2,   130] loss: 3.020 (2.923 0.097 3.315) (np: 52.1, max-t: 0.223) [wd: 4.01e-02] [lr: 2.64e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   130] grad_stats: [0.00e+00 0.00e+00] (5.14e+00, 2.18e+01)
INFO:root:[2,   140] loss: 3.011 (2.915 0.096 3.309) (np: 52.2, max-t: 0.224) [wd: 4.01e-02] [lr: 2.65e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   140] grad_stats: [0.00e+00 0.00e+00] (3.90e+00, 1.58e+01)
INFO:root:[2,   150] loss: 3.007 (2.910 0.097 3.306) (np: 52.2, max-t: 0.225) [wd: 4.01e-02] [lr: 2.65e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   150] grad_stats: [0.00e+00 0.00e+00] (6.63e+00, 2.80e+01)
INFO:root:[2,   160] loss: 3.002 (2.904 0.098 3.300) (np: 52.2, max-t: 0.225) [wd: 4.01e-02] [lr: 2.66e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   160] grad_stats: [0.00e+00 0.00e+00] (5.03e+00, 2.05e+01)
INFO:root:[2,   170] loss: 2.996 (2.898 0.099 3.295) (np: 52.3, max-t: 0.227) [wd: 4.01e-02] [lr: 2.67e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   170] grad_stats: [0.00e+00 0.00e+00] (8.04e+00, 3.35e+01)
INFO:root:[2,   180] loss: 2.987 (2.888 0.099 3.288) (np: 52.3, max-t: 0.228) [wd: 4.01e-02] [lr: 2.68e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   180] grad_stats: [0.00e+00 0.00e+00] (6.04e+00, 2.50e+01)
INFO:root:[2,   190] loss: 2.981 (2.881 0.100 3.283) (np: 52.4, max-t: 0.230) [wd: 4.01e-02] [lr: 2.69e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   190] grad_stats: [0.00e+00 0.00e+00] (5.63e+00, 2.45e+01)
INFO:root:[2,   200] loss: 2.973 (2.873 0.100 3.277) (np: 52.5, max-t: 0.232) [wd: 4.01e-02] [lr: 2.69e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   200] grad_stats: [0.00e+00 0.00e+00] (4.56e+00, 1.89e+01)
INFO:root:[2,   210] loss: 2.967 (2.866 0.101 3.271) (np: 52.6, max-t: 0.234) [wd: 4.01e-02] [lr: 2.70e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   210] grad_stats: [0.00e+00 0.00e+00] (6.95e+00, 2.96e+01)
INFO:root:[2,   220] loss: 2.961 (2.860 0.101 3.267) (np: 52.6, max-t: 0.235) [wd: 4.01e-02] [lr: 2.71e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   220] grad_stats: [0.00e+00 0.00e+00] (7.21e+00, 3.20e+01)
INFO:root:[2,   230] loss: 2.958 (2.855 0.103 3.261) (np: 52.7, max-t: 0.236) [wd: 4.01e-02] [lr: 2.72e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   230] grad_stats: [0.00e+00 0.00e+00] (8.79e+00, 3.85e+01)
INFO:root:[2,   240] loss: 2.951 (2.849 0.102 3.257) (np: 52.7, max-t: 0.238) [wd: 4.01e-02] [lr: 2.73e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   240] grad_stats: [0.00e+00 0.00e+00] (1.03e+01, 4.66e+01)
INFO:root:[2,   250] loss: 2.944 (2.842 0.102 3.251) (np: 52.8, max-t: 0.239) [wd: 4.01e-02] [lr: 2.73e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   250] grad_stats: [0.00e+00 0.00e+00] (5.17e+00, 2.17e+01)
INFO:root:[2,   260] loss: 2.939 (2.836 0.103 3.247) (np: 52.9, max-t: 0.241) [wd: 4.01e-02] [lr: 2.74e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   260] grad_stats: [0.00e+00 0.00e+00] (8.54e+00, 3.96e+01)
INFO:root:[2,   270] loss: 2.933 (2.830 0.103 3.242) (np: 53.0, max-t: 0.242) [wd: 4.01e-02] [lr: 2.75e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   270] grad_stats: [0.00e+00 0.00e+00] (8.05e+00, 3.86e+01)
INFO:root:[2,   280] loss: 2.929 (2.826 0.103 3.238) (np: 53.1, max-t: 0.243) [wd: 4.01e-02] [lr: 2.76e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   280] grad_stats: [0.00e+00 0.00e+00] (6.91e+00, 3.33e+01)
INFO:root:[2,   290] loss: 2.923 (2.819 0.104 3.233) (np: 53.1, max-t: 0.244) [wd: 4.01e-02] [lr: 2.77e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   290] grad_stats: [0.00e+00 0.00e+00] (6.22e+00, 2.74e+01)
INFO:root:[2,   300] loss: 2.919 (2.815 0.104 3.228) (np: 53.1, max-t: 0.245) [wd: 4.01e-02] [lr: 2.77e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   300] grad_stats: [0.00e+00 0.00e+00] (5.23e+00, 2.15e+01)
INFO:root:[2,   310] loss: 2.913 (2.809 0.104 3.223) (np: 53.1, max-t: 0.246) [wd: 4.01e-02] [lr: 2.78e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   310] grad_stats: [0.00e+00 0.00e+00] (8.99e+00, 4.66e+01)
INFO:root:[2,   320] loss: 2.909 (2.804 0.105 3.218) (np: 53.2, max-t: 0.247) [wd: 4.01e-02] [lr: 2.79e-04] [mem: 1.60e+03] (41 ms; 21 ms)
INFO:root:[2,   320] grad_stats: [0.00e+00 0.00e+00] (4.63e+00, 2.02e+01)
INFO:root:[2,   330] loss: 2.904 (2.798 0.106 3.213) (np: 53.2, max-t: 0.248) [wd: 4.01e-02] [lr: 2.80e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   330] grad_stats: [0.00e+00 0.00e+00] (4.35e+00, 1.94e+01)
INFO:root:[2,   340] loss: 2.899 (2.793 0.106 3.208) (np: 53.2, max-t: 0.249) [wd: 4.01e-02] [lr: 2.81e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   340] grad_stats: [0.00e+00 0.00e+00] (8.67e+00, 3.94e+01)
INFO:root:[2,   350] loss: 2.896 (2.789 0.107 3.204) (np: 53.3, max-t: 0.250) [wd: 4.01e-02] [lr: 2.81e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   350] grad_stats: [0.00e+00 0.00e+00] (6.46e+00, 2.84e+01)
INFO:root:[2,   360] loss: 2.890 (2.783 0.107 3.200) (np: 53.4, max-t: 0.252) [wd: 4.01e-02] [lr: 2.82e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   360] grad_stats: [0.00e+00 0.00e+00] (6.19e+00, 2.95e+01)
INFO:root:[2,   370] loss: 2.887 (2.779 0.108 3.195) (np: 53.5, max-t: 0.253) [wd: 4.01e-02] [lr: 2.83e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   370] grad_stats: [0.00e+00 0.00e+00] (9.79e+00, 5.10e+01)
INFO:root:[2,   380] loss: 2.883 (2.775 0.108 3.191) (np: 53.5, max-t: 0.254) [wd: 4.01e-02] [lr: 2.84e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   380] grad_stats: [0.00e+00 0.00e+00] (1.24e+01, 6.46e+01)
INFO:root:[2,   390] loss: 2.878 (2.770 0.108 3.187) (np: 53.6, max-t: 0.255) [wd: 4.01e-02] [lr: 2.85e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   390] grad_stats: [0.00e+00 0.00e+00] (7.22e+00, 3.49e+01)
INFO:root:[2,   400] loss: 2.873 (2.764 0.109 3.182) (np: 53.7, max-t: 0.256) [wd: 4.01e-02] [lr: 2.85e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   400] grad_stats: [0.00e+00 0.00e+00] (6.64e+00, 3.35e+01)
INFO:root:[2,   410] loss: 2.868 (2.759 0.109 3.178) (np: 53.8, max-t: 0.257) [wd: 4.01e-02] [lr: 2.86e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   410] grad_stats: [0.00e+00 0.00e+00] (4.29e+00, 1.85e+01)
INFO:root:[2,   420] loss: 2.866 (2.756 0.109 3.175) (np: 53.8, max-t: 0.258) [wd: 4.02e-02] [lr: 2.87e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   420] grad_stats: [0.00e+00 0.00e+00] (6.77e+00, 3.02e+01)
INFO:root:[2,   430] loss: 2.860 (2.751 0.109 3.170) (np: 53.8, max-t: 0.259) [wd: 4.02e-02] [lr: 2.88e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   430] grad_stats: [0.00e+00 0.00e+00] (5.69e+00, 2.55e+01)
INFO:root:[2,   440] loss: 2.859 (2.748 0.111 3.167) (np: 53.9, max-t: 0.261) [wd: 4.02e-02] [lr: 2.89e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   440] grad_stats: [0.00e+00 0.00e+00] (1.53e+01, 8.28e+01)
INFO:root:[2,   450] loss: 2.854 (2.743 0.111 3.163) (np: 54.0, max-t: 0.262) [wd: 4.02e-02] [lr: 2.89e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   450] grad_stats: [0.00e+00 0.00e+00] (4.94e+00, 2.28e+01)
INFO:root:[2,   460] loss: 2.849 (2.738 0.111 3.159) (np: 54.0, max-t: 0.263) [wd: 4.02e-02] [lr: 2.90e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   460] grad_stats: [0.00e+00 0.00e+00] (8.28e+00, 4.52e+01)
INFO:root:[2,   470] loss: 2.845 (2.733 0.112 3.155) (np: 54.1, max-t: 0.264) [wd: 4.02e-02] [lr: 2.91e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   470] grad_stats: [0.00e+00 0.00e+00] (5.37e+00, 2.69e+01)
INFO:root:[2,   480] loss: 2.840 (2.728 0.112 3.150) (np: 54.1, max-t: 0.265) [wd: 4.02e-02] [lr: 2.92e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   480] grad_stats: [0.00e+00 0.00e+00] (1.11e+01, 5.21e+01)
INFO:root:[2,   490] loss: 2.835 (2.722 0.112 3.146) (np: 54.2, max-t: 0.266) [wd: 4.02e-02] [lr: 2.93e-04] [mem: 1.60e+03] (42 ms; 22 ms)
INFO:root:[2,   490] grad_stats: [0.00e+00 0.00e+00] (5.00e+00, 2.24e+01)
INFO:root:[2,   500] loss: 2.831 (2.718 0.113 3.142) (np: 54.2, max-t: 0.267) [wd: 4.02e-02] [lr: 2.93e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   500] grad_stats: [0.00e+00 0.00e+00] (6.42e+00, 2.93e+01)
INFO:root:[2,   510] loss: 2.826 (2.713 0.113 3.137) (np: 54.3, max-t: 0.269) [wd: 4.02e-02] [lr: 2.94e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   510] grad_stats: [0.00e+00 0.00e+00] (6.20e+00, 3.57e+01)
INFO:root:[2,   520] loss: 2.822 (2.709 0.114 3.134) (np: 54.3, max-t: 0.270) [wd: 4.02e-02] [lr: 2.95e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   520] grad_stats: [0.00e+00 0.00e+00] (7.69e+00, 4.46e+01)
INFO:root:[2,   530] loss: 2.819 (2.705 0.114 3.130) (np: 54.4, max-t: 0.271) [wd: 4.02e-02] [lr: 2.96e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   530] grad_stats: [0.00e+00 0.00e+00] (7.23e+00, 5.28e+01)
INFO:root:[2,   540] loss: 2.814 (2.700 0.114 3.126) (np: 54.5, max-t: 0.272) [wd: 4.02e-02] [lr: 2.97e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   540] grad_stats: [0.00e+00 0.00e+00] (8.31e+00, 4.33e+01)
INFO:root:[2,   550] loss: 2.810 (2.696 0.115 3.122) (np: 54.6, max-t: 0.273) [wd: 4.02e-02] [lr: 2.97e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   550] grad_stats: [0.00e+00 0.00e+00] (8.44e+00, 4.63e+01)
INFO:root:[2,   560] loss: 2.806 (2.691 0.115 3.118) (np: 54.6, max-t: 0.274) [wd: 4.02e-02] [lr: 2.98e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   560] grad_stats: [0.00e+00 0.00e+00] (8.01e+00, 5.45e+01)
INFO:root:[2,   570] loss: 2.802 (2.687 0.115 3.114) (np: 54.7, max-t: 0.275) [wd: 4.02e-02] [lr: 2.99e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   570] grad_stats: [0.00e+00 0.00e+00] (4.04e+00, 1.83e+01)
INFO:root:[2,   580] loss: 2.797 (2.681 0.116 3.109) (np: 54.7, max-t: 0.276) [wd: 4.02e-02] [lr: 3.00e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   580] grad_stats: [0.00e+00 0.00e+00] (6.12e+00, 3.09e+01)
INFO:root:[2,   590] loss: 2.793 (2.677 0.116 3.105) (np: 54.8, max-t: 0.277) [wd: 4.02e-02] [lr: 3.01e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   590] grad_stats: [0.00e+00 0.00e+00] (7.21e+00, 4.88e+01)
INFO:root:[2,   600] loss: 2.791 (2.674 0.117 3.102) (np: 54.8, max-t: 0.278) [wd: 4.02e-02] [lr: 3.01e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   600] grad_stats: [0.00e+00 0.00e+00] (7.67e+00, 5.51e+01)
INFO:root:[2,   610] loss: 2.785 (2.668 0.117 3.098) (np: 54.9, max-t: 0.280) [wd: 4.02e-02] [lr: 3.02e-04] [mem: 1.60e+03] (43 ms; 22 ms)
INFO:root:[2,   610] grad_stats: [0.00e+00 0.00e+00] (4.92e+00, 2.39e+01)
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale motor response
INFO:root:6 O
INFO:root:Glascow coma scale eye opening
INFO:root:4 S
INFO:root:Glascow coma scale motor response
INFO:root:6 O
/ext3/medfuse/lib/python3.6/site-packages/torch/nn/modules/rnn.py:683: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448272031/work/aten/src/ATen/native/cudnn/RNN.cpp:924.)
  self.num_layers, self.dropout, self.training, self.bidirectional)
--- Logging error ---
Traceback (most recent call last):
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 82, in write
    category_id = self._possible_values[channel].index(value)
ValueError: '6 O' is not in list

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 117, in transform
    write(data, bin_id, channel, row[j], begin_pos)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 88, in write
    category_id = self._possible_values[channel].index(value)
ValueError: '6 O' is not in list

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 994, in emit
    msg = self.format(record)
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 840, in format
    return fmt.format(record)
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 577, in format
    record.message = record.getMessage()
  File "/ext3/medfuse/lib/python3.6/logging/__init__.py", line 338, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/ext3/medfuse/lib/python3.6/multiprocessing/spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "/ext3/medfuse/lib/python3.6/multiprocessing/spawn.py", line 118, in _main
    return self._bootstrap()
  File "/ext3/medfuse/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/ext3/medfuse/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/main.py", line 69, in process_main
    return msn(params, medfuse_args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/msn_train.py", line 336, in main
    # logger.info(itr)
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_dataset.py", line 98, in __getitem__
    data[i] = self.discretizer.transform(data[i], end=ts)[0]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 119, in transform
    logger.info(channel, row[j])
Message: 'Glascow coma scale motor response'
Arguments: ('6 O',)
Traceback (most recent call last):
  File "main.py", line 84, in <module>
    args=(args.fname, num_gpus, args.devices, args.modality, args))
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 82, in write
    category_id = self._possible_values[channel].index(value)
ValueError: '6 O' is not in list

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/main.py", line 69, in process_main
    return msn(params, medfuse_args)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/msn_train.py", line 336, in main
    # logger.info(itr)
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/ext3/medfuse/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_dataset.py", line 98, in __getitem__
    data[i] = self.discretizer.transform(data[i], end=ts)[0]
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 142, in transform
    write(data, bin_id, channel, imputed_value, begin_pos)
  File "/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/ehr_utils/preprocessing.py", line 88, in write
    category_id = self._possible_values[channel].index(value)
ValueError: '6 O' is not in list

