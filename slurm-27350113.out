INFO:root:loaded params...
{   'data': {'image_folder': '/imagenet/', 'num_classes': 25, 'root_path': '.'},
    'logging': {   'folder': './checkpoint/msn_ehr_logs/',
                   'pretrain_path': '/scratch/projects/shamoutlab/ds5749/multi-modal-msn/checkpoint/msn_ehr_logs/msn-ehr-experiment-vertical_horizontal-ep100.pth.tar',
                   'write_tag': 'msn-lineval-experiment-ehr'},
    'meta': {   'copy_data': False,
                'device': 'cuda:0',
                'load_checkpoint': True,
                'master_port': 8888,
                'model_name': 'LSTM',
                'training': True},
    'optimization': {   'epochs': 100,
                        'lr': 6.4,
                        'normalize': True,
                        'num_blocks': 1,
                        'weight_decay': 0.0}}
INFO:root:Running linear-evaluation
INFO:root:MIMICCXR ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='configs/eval/medfuse_ehr.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, modality='ehr', mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:MIMICCXR ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='configs/eval/medfuse_ehr.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, modality='ehr', mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:initialized data-loader (ipe 333)
INFO:root:initialized val data-loader (ipe 37)
INFO:root:key "LayerNorm.weight" could not be found in loaded state dict
INFO:root:key "LayerNorm.bias" could not be found in loaded state dict
INFO:root:loaded pretrained model with msg: _IncompatibleKeys(missing_keys=['LayerNorm.weight', 'LayerNorm.bias'], unexpected_keys=['fc.fc1.weight', 'fc.fc1.bias', 'fc.bn1.weight', 'fc.bn1.bias', 'fc.bn1.running_mean', 'fc.bn1.running_var', 'fc.bn1.num_batches_tracked', 'fc.fc2.weight', 'fc.fc2.bias', 'fc.bn2.weight', 'fc.bn2.bias', 'fc.bn2.running_mean', 'fc.bn2.running_var', 'fc.bn2.num_batches_tracked', 'fc.fc3.weight', 'fc.fc3.bias'])
INFO:root:loaded pretrained encoder from epoch: 99 path: /scratch/projects/shamoutlab/ds5749/multi-modal-msn/checkpoint/msn_ehr_logs/msn-ehr-experiment-vertical_horizontal-ep100.pth.tar
INFO:root:LSTM(
  (layer0): LSTM(76, 128, batch_first=True)
  (dense_layer): Linear(in_features=128, out_features=128, bias=True)
  (LayerNorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
)
INFO:root:putting model in eval mode
INFO:root:122240
INFO:root:epoch: 332
INFO:root:train metrics
INFO:root:auc_scores
INFO:root:[0.53645023 0.63710753 0.50558893 0.51623809 0.51520848 0.51283513
 0.51654902 0.51213077 0.51028604 0.5193658  0.50825393 0.51733044
 0.5123911  0.50980654 0.53286011 0.51282206 0.50392456 0.5098761
 0.50841361 0.52777391 0.52435694 0.55866348 0.58827119 0.55382671
 0.58282109]
INFO:root:auroc_mean
INFO:root:0.5293260708685691
INFO:root:auprc_mean
INFO:root:0.20112543598173122
INFO:root:auprc_scores
INFO:root:[0.29492681 0.10979228 0.0775041  0.33630647 0.21610008 0.14827324
 0.19922911 0.10394667 0.25950793 0.32514012 0.11584585 0.18207478
 0.41248525 0.42437521 0.39939193 0.07483323 0.21669812 0.13256376
 0.09962906 0.0556754  0.07339286 0.15782375 0.22629508 0.19832442
 0.18800038]
INFO:root:ci_auroc
INFO:root:[(0.5301200050192878, 0.5425799108454763), (0.6245277164463758, 0.650771024434831), (0.4952932665847081, 0.5159099868640441), (0.5101074031169083, 0.5219698838858081), (0.5082832873209701, 0.5226597694192135), (0.5049965829285675, 0.5204533917575399), (0.5098195505131061, 0.5236437972578569), (0.5034691247362518, 0.5207866490976767), (0.5040738355230936, 0.5164786459087163), (0.5134233509939141, 0.5253959457954571), (0.49971262446017745, 0.5170007799168108), (0.509685564926878, 0.5251258095887749), (0.5069236925081162, 0.5178563817504118), (0.5043436705051724, 0.5152084112427424), (0.5275115005180883, 0.5383625569119136), (0.5016839798613174, 0.5232922419791275), (0.4972752658242649, 0.5105429103732108), (0.5013447945693685, 0.5183346223272063), (0.4989528884663111, 0.5186096281654107), (0.5142959096912672, 0.5406935039463585), (0.513433800930547, 0.5360618016644816), (0.5498878957047766, 0.5672869254983206), (0.5806392090720752, 0.5964644859659243), (0.5455953051521183, 0.5614291598197456), (0.5739206676688625, 0.5916325467494822)]
INFO:root:ci_auprc
INFO:root:[(0.2884004901148039, 0.3015422460396245), (0.10251453260251608, 0.11872477076705003), (0.07396160772965282, 0.08164395114618903), (0.3302778840800641, 0.3428603758993309), (0.21061213110601795, 0.22211988998535748), (0.1438000772004331, 0.15343219247776807), (0.19414189574287363, 0.20499125891660586), (0.10007114088595526, 0.108423832422037), (0.2532542920303779, 0.26556248294492846), (0.31863005400212324, 0.33177615673482314), (0.1118037621035474, 0.1204389785879488), (0.17645657446400043, 0.18800195958628882), (0.40600377237054125, 0.4191094157126524), (0.417407873577953, 0.43133623437491625), (0.39239621176069667, 0.40647853306306303), (0.07125882193721168, 0.07890340000802447), (0.21105389873332706, 0.22262267796650168), (0.127687921731259, 0.13783885754022676), (0.09542720984386376, 0.10431150771974332), (0.05219637683135616, 0.05993171923362191), (0.07012360910515339, 0.0772327918058339), (0.15192990729678563, 0.16427373734153058), (0.21824830098712866, 0.2347309481976282), (0.19093961744847018, 0.20586018776130732), (0.17943096698059222, 0.19751183428096358)]

INFO:root:val metrics
INFO:root:auc_scores
INFO:root:[0.61027019 0.728588   0.59248396 0.56675321 0.55576793 0.57456998
 0.59967445 0.59254195 0.58905269 0.60349606 0.57552189 0.54853809
 0.5787043  0.54117674 0.60331803 0.56217738 0.55194441 0.577265
 0.56775428 0.57087293 0.59756177 0.673027   0.70863669 0.6624016
 0.69518997]
INFO:root:auroc_mean
INFO:root:0.601091541204105
INFO:root:auprc_mean
INFO:root:0.24771788696810793
INFO:root:auprc_scores
INFO:root:[0.36370065 0.1516493  0.10051912 0.35009821 0.23715254 0.17731651
 0.25029842 0.13627492 0.32040878 0.40289362 0.14972795 0.19568809
 0.47597568 0.441981   0.47835069 0.08201978 0.25071916 0.174672
 0.12131507 0.07747211 0.09146359 0.22379709 0.33835823 0.27681199
 0.32428267]
INFO:root:ci_auroc
INFO:root:[(0.5928970702700651, 0.6274557664771684), (0.6916220716462207, 0.7655730906284786), (0.5630383220901384, 0.6220320928359684), (0.5497574045805219, 0.5841255837329635), (0.5347768354706632, 0.5746721390603954), (0.5518823912083263, 0.5970130552445689), (0.5797061425637204, 0.6187850128431472), (0.5677131841892924, 0.6155751381990636), (0.5698459074056748, 0.6080156343790828), (0.5859823904713911, 0.6197681596865594), (0.5506213004687782, 0.5985410314979911), (0.5274679435466759, 0.5691620301353497), (0.5618675080161228, 0.5943313883938296), (0.5248556421406552, 0.5564029238033553), (0.5875840067618309, 0.6189473006298577), (0.5288411868690659, 0.5956747712480424), (0.5325651327593185, 0.5710241650952286), (0.5527964406385552, 0.6006596624853768), (0.5413876181499028, 0.5937309411485617), (0.5339315018219771, 0.6078539786544399), (0.5678016784869304, 0.6290485892256226), (0.649834628049957, 0.6971602304230297), (0.6884512331259495, 0.7289023546710717), (0.6405372134455651, 0.6826969880228921), (0.6729441018950891, 0.7164785782060265)]
INFO:root:ci_auprc
INFO:root:[(0.3401655517145902, 0.39084518794111717), (0.12076783229106783, 0.19868727105227713), (0.08731780443268067, 0.12017684540040943), (0.3314754557664997, 0.3719688352941081), (0.21946310527061394, 0.2595593043824573), (0.1614596798177309, 0.19706098239075082), (0.23142622546973046, 0.2737788440419769), (0.12066413493025804, 0.15552169006263217), (0.2992948332845769, 0.34422850375341973), (0.38138408033872345, 0.4266697492220825), (0.13492952139844094, 0.16752473879828458), (0.17908141202228703, 0.21565812617801783), (0.45633409102370487, 0.4980416784018377), (0.4217018070152405, 0.46423486751741266), (0.45489673467231156, 0.5006132992038335), (0.0707709652874155, 0.09650783481729726), (0.23239224899371222, 0.26985116061856407), (0.1545805076786176, 0.20208329994866545), (0.10665184642400943, 0.13800355699566963), (0.0644005520676957, 0.09704575259018727), (0.07926610444315693, 0.11020282334714201), (0.2005870904556496, 0.2559340639910487), (0.3064286147187984, 0.3738821956141069), (0.24964967374302577, 0.3097166417481959), (0.2850623877472114, 0.3638661362775934)]
mefuse_linear_eval.py:351: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  inputs, labels = torch.tensor(data[0]).to(device), torch.tensor(data[1]).to(device)
