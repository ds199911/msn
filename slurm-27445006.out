INFO:root:loaded params...
{   'data': {'image_folder': '/imagenet/', 'num_classes': 25, 'root_path': '.'},
    'logging': {   'folder': './checkpoint/msn_ehr_logs/',
                   'pretrain_path': '/scratch/projects/shamoutlab/ds5749/multi-modal-msn/checkpoint/msn_ehr_logs/msn-ehr-experiment-vertical_and_horizontal_dropstart-64-ep100.pth.tar',
                   'write_tag': 'msn-lineval-experiment-ehr'},
    'meta': {   'copy_data': False,
                'device': 'cuda:0',
                'load_checkpoint': True,
                'master_port': 8888,
                'model_name': 'LSTM',
                'training': True},
    'optimization': {   'epochs': 100,
                        'lr': 6.4,
                        'normalize': True,
                        'num_blocks': 1,
                        'weight_decay': 0.0}}
INFO:root:Running linear-evaluation
INFO:root:MIMICCXR ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='configs/eval/medfuse_ehr.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, modality='ehr', mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:MIMICCXR ehr fusion dataset
INFO:root:Namespace(align=0.0, batch_size=64, beta_1=0.9, crop=224, cxr_data_dir='/data/MedFuse/2.0.0', daft_activation='linear', data_pairs='partial_ehr_cxr', data_ratio=1.0, depth=1, dim=256, dropout=0.0, ehr_data_dir='/data/MedFuse/mimic-iv-extracted', epochs=100, eval=False, fname='configs/eval/medfuse_ehr.yaml', fusion='joint', fusion_type='lstm', imputation='previous', labels_set='pheno', layer_after=4, layers=1, load_state=None, load_state_cxr=None, load_state_ehr=None, lr=0.0001, missing_token=None, mmtm_ratio=4, modality='ehr', mode='train', network=None, normalizer_state='/scratch/projects/shamoutlab/ds5749/multi-modal-msn/src/medfuse/normalizers/ph_ts1.0.input_str:previous.start_time:zero.normalizer', num_classes=25, patience=15, pretrained=False, rec_dropout=0.0, resize=256, resume=False, save_dir='checkpoints', task='phenotyping', timestep=1.0, vision_backbone='densenet121', vision_num_classes=14)
INFO:root:partial_ehr_cxrlstm
INFO:root:MIMICCXR dataset created
INFO:root:unsupervised data loader created
INFO:root:initialized data-loader (ipe 333)
INFO:root:initialized val data-loader (ipe 37)
INFO:root:loaded pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.fc1.weight', 'fc.fc1.bias', 'fc.bn1.weight', 'fc.bn1.bias', 'fc.bn1.running_mean', 'fc.bn1.running_var', 'fc.bn1.num_batches_tracked', 'fc.fc2.weight', 'fc.fc2.bias', 'fc.bn2.weight', 'fc.bn2.bias', 'fc.bn2.running_mean', 'fc.bn2.running_var', 'fc.bn2.num_batches_tracked', 'fc.fc3.weight', 'fc.fc3.bias'])
INFO:root:loaded pretrained encoder from epoch: 99 path: /scratch/projects/shamoutlab/ds5749/multi-modal-msn/checkpoint/msn_ehr_logs/msn-ehr-experiment-vertical_and_horizontal_dropstart-64-ep100.pth.tar
INFO:root:LSTM(
  (layer0): LSTM(76, 128, batch_first=True)
  (dense_layer): Linear(in_features=128, out_features=128, bias=True)
  (LayerNorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
)
INFO:root:putting model in eval mode
INFO:root:122240
INFO:root:epoch: 0
INFO:root:epoch: 1
INFO:root:epoch: 2
INFO:root:epoch: 3
INFO:root:epoch: 4
INFO:root:epoch: 5
INFO:root:epoch: 6
INFO:root:epoch: 7
INFO:root:epoch: 8
INFO:root:epoch: 9
INFO:root:epoch: 10
INFO:root:epoch: 11
INFO:root:epoch: 12
INFO:root:epoch: 13
INFO:root:epoch: 14
INFO:root:epoch: 15
INFO:root:epoch: 16
INFO:root:epoch: 17
INFO:root:epoch: 18
INFO:root:epoch: 19
INFO:root:epoch: 20
INFO:root:epoch: 21
INFO:root:epoch: 22
INFO:root:epoch: 23
INFO:root:epoch: 24
INFO:root:epoch: 25
INFO:root:epoch: 26
INFO:root:epoch: 27
INFO:root:epoch: 28
INFO:root:epoch: 29
INFO:root:epoch: 30
INFO:root:epoch: 31
INFO:root:epoch: 32
INFO:root:epoch: 33
INFO:root:epoch: 34
INFO:root:epoch: 35
INFO:root:epoch: 36
INFO:root:epoch: 37
INFO:root:epoch: 38
INFO:root:epoch: 39
INFO:root:epoch: 40
INFO:root:epoch: 41
INFO:root:epoch: 42
INFO:root:epoch: 43
INFO:root:epoch: 44
INFO:root:epoch: 45
INFO:root:epoch: 46
INFO:root:epoch: 47
INFO:root:epoch: 48
INFO:root:epoch: 49
INFO:root:epoch: 50
INFO:root:epoch: 51
INFO:root:epoch: 52
INFO:root:epoch: 53
INFO:root:epoch: 54
INFO:root:epoch: 55
INFO:root:epoch: 56
INFO:root:epoch: 57
INFO:root:epoch: 58
INFO:root:epoch: 59
INFO:root:epoch: 60
INFO:root:epoch: 61
INFO:root:epoch: 62
INFO:root:epoch: 63
INFO:root:epoch: 64
INFO:root:epoch: 65
INFO:root:epoch: 66
INFO:root:epoch: 67
INFO:root:epoch: 68
INFO:root:epoch: 69
INFO:root:epoch: 70
INFO:root:epoch: 71
INFO:root:epoch: 72
INFO:root:epoch: 73
INFO:root:epoch: 74
INFO:root:epoch: 75
INFO:root:epoch: 76
INFO:root:epoch: 77
INFO:root:epoch: 78
INFO:root:epoch: 79
INFO:root:epoch: 80
INFO:root:epoch: 81
INFO:root:epoch: 82
INFO:root:epoch: 83
INFO:root:epoch: 84
INFO:root:epoch: 85
INFO:root:epoch: 86
INFO:root:epoch: 87
INFO:root:epoch: 88
INFO:root:epoch: 89
INFO:root:epoch: 90
INFO:root:epoch: 91
INFO:root:epoch: 92
INFO:root:epoch: 93
INFO:root:epoch: 94
INFO:root:epoch: 95
INFO:root:epoch: 96
INFO:root:epoch: 97
INFO:root:epoch: 98
INFO:root:epoch: 99
INFO:root:epoch: 100
INFO:root:epoch: 101
INFO:root:epoch: 102
INFO:root:epoch: 103
INFO:root:epoch: 104
INFO:root:epoch: 105
INFO:root:epoch: 106
INFO:root:epoch: 107
INFO:root:epoch: 108
INFO:root:epoch: 109
INFO:root:epoch: 110
INFO:root:epoch: 111
INFO:root:epoch: 112
INFO:root:epoch: 113
INFO:root:epoch: 114
INFO:root:epoch: 115
INFO:root:epoch: 116
INFO:root:epoch: 117
INFO:root:epoch: 118
INFO:root:epoch: 119
INFO:root:epoch: 120
INFO:root:epoch: 121
INFO:root:epoch: 122
INFO:root:epoch: 123
INFO:root:epoch: 124
INFO:root:epoch: 125
INFO:root:epoch: 126
INFO:root:epoch: 127
INFO:root:epoch: 128
INFO:root:epoch: 129
INFO:root:epoch: 130
INFO:root:epoch: 131
INFO:root:epoch: 132
INFO:root:epoch: 133
INFO:root:epoch: 134
INFO:root:epoch: 135
INFO:root:epoch: 136
INFO:root:epoch: 137
INFO:root:epoch: 138
INFO:root:epoch: 139
INFO:root:epoch: 140
INFO:root:epoch: 141
INFO:root:epoch: 142
INFO:root:epoch: 143
INFO:root:epoch: 144
INFO:root:epoch: 145
INFO:root:epoch: 146
INFO:root:epoch: 147
INFO:root:epoch: 148
INFO:root:epoch: 149
INFO:root:epoch: 150
INFO:root:epoch: 151
INFO:root:epoch: 152
INFO:root:epoch: 153
INFO:root:epoch: 154
INFO:root:epoch: 155
INFO:root:epoch: 156
INFO:root:epoch: 157
INFO:root:epoch: 158
INFO:root:epoch: 159
INFO:root:epoch: 160
INFO:root:epoch: 161
INFO:root:epoch: 162
INFO:root:epoch: 163
INFO:root:epoch: 164
INFO:root:epoch: 165
INFO:root:epoch: 166
INFO:root:epoch: 167
INFO:root:epoch: 168
INFO:root:epoch: 169
INFO:root:epoch: 170
INFO:root:epoch: 171
INFO:root:epoch: 172
INFO:root:epoch: 173
INFO:root:epoch: 174
INFO:root:epoch: 175
INFO:root:epoch: 176
INFO:root:epoch: 177
INFO:root:epoch: 178
INFO:root:epoch: 179
INFO:root:epoch: 180
INFO:root:epoch: 181
INFO:root:epoch: 182
INFO:root:epoch: 183
INFO:root:epoch: 184
INFO:root:epoch: 185
INFO:root:epoch: 186
INFO:root:epoch: 187
INFO:root:epoch: 188
INFO:root:epoch: 189
INFO:root:epoch: 190
INFO:root:epoch: 191
INFO:root:epoch: 192
INFO:root:epoch: 193
INFO:root:epoch: 194
INFO:root:epoch: 195
INFO:root:epoch: 196
INFO:root:epoch: 197
INFO:root:epoch: 198
INFO:root:epoch: 199
INFO:root:epoch: 200
INFO:root:epoch: 201
INFO:root:epoch: 202
INFO:root:epoch: 203
INFO:root:epoch: 204
INFO:root:epoch: 205
INFO:root:epoch: 206
INFO:root:epoch: 207
INFO:root:epoch: 208
INFO:root:epoch: 209
INFO:root:epoch: 210
INFO:root:epoch: 211
INFO:root:epoch: 212
INFO:root:epoch: 213
INFO:root:epoch: 214
INFO:root:epoch: 215
INFO:root:epoch: 216
INFO:root:epoch: 217
INFO:root:epoch: 218
INFO:root:epoch: 219
INFO:root:epoch: 220
INFO:root:epoch: 221
INFO:root:epoch: 222
INFO:root:epoch: 223
INFO:root:epoch: 224
INFO:root:epoch: 225
INFO:root:epoch: 226
INFO:root:epoch: 227
INFO:root:epoch: 228
INFO:root:epoch: 229
INFO:root:epoch: 230
INFO:root:epoch: 231
INFO:root:epoch: 232
INFO:root:epoch: 233
INFO:root:epoch: 234
INFO:root:epoch: 235
INFO:root:epoch: 236
INFO:root:epoch: 237
INFO:root:epoch: 238
INFO:root:epoch: 239
INFO:root:epoch: 240
INFO:root:epoch: 241
INFO:root:epoch: 242
INFO:root:epoch: 243
INFO:root:epoch: 244
INFO:root:epoch: 245
INFO:root:epoch: 246
INFO:root:epoch: 247
INFO:root:epoch: 248
INFO:root:epoch: 249
INFO:root:epoch: 250
INFO:root:epoch: 251
INFO:root:epoch: 252
INFO:root:epoch: 253
INFO:root:epoch: 254
INFO:root:epoch: 255
INFO:root:epoch: 256
INFO:root:epoch: 257
INFO:root:epoch: 258
INFO:root:epoch: 259
INFO:root:epoch: 260
INFO:root:epoch: 261
INFO:root:epoch: 262
INFO:root:epoch: 263
INFO:root:epoch: 264
INFO:root:epoch: 265
INFO:root:epoch: 266
INFO:root:epoch: 267
INFO:root:epoch: 268
INFO:root:epoch: 269
INFO:root:epoch: 270
INFO:root:epoch: 271
INFO:root:epoch: 272
INFO:root:epoch: 273
INFO:root:epoch: 274
INFO:root:epoch: 275
INFO:root:epoch: 276
INFO:root:epoch: 277
INFO:root:epoch: 278
INFO:root:epoch: 279
INFO:root:epoch: 280
INFO:root:epoch: 281
INFO:root:epoch: 282
INFO:root:epoch: 283
INFO:root:epoch: 284
INFO:root:epoch: 285
INFO:root:epoch: 286
INFO:root:epoch: 287
INFO:root:epoch: 288
INFO:root:epoch: 289
INFO:root:epoch: 290
INFO:root:epoch: 291
INFO:root:epoch: 292
INFO:root:epoch: 293
INFO:root:epoch: 294
INFO:root:epoch: 295
INFO:root:epoch: 296
INFO:root:epoch: 297
INFO:root:epoch: 298
INFO:root:epoch: 299
INFO:root:epoch: 300
INFO:root:epoch: 301
INFO:root:epoch: 302
INFO:root:epoch: 303
INFO:root:epoch: 304
INFO:root:epoch: 305
INFO:root:epoch: 306
INFO:root:epoch: 307
INFO:root:epoch: 308
INFO:root:epoch: 309
INFO:root:epoch: 310
INFO:root:epoch: 311
INFO:root:epoch: 312
INFO:root:epoch: 313
INFO:root:epoch: 314
INFO:root:epoch: 315
INFO:root:epoch: 316
INFO:root:epoch: 317
INFO:root:epoch: 318
INFO:root:epoch: 319
INFO:root:epoch: 320
INFO:root:epoch: 321
INFO:root:epoch: 322
INFO:root:epoch: 323
INFO:root:epoch: 324
INFO:root:epoch: 325
INFO:root:epoch: 326
INFO:root:epoch: 327
INFO:root:epoch: 328
INFO:root:epoch: 329
INFO:root:epoch: 330
INFO:root:epoch: 331
INFO:root:epoch: 332
INFO:root:train metrics
INFO:root:auc_scores
INFO:root:[0.53215627 0.62569105 0.51349725 0.51698739 0.51055556 0.51378211
 0.51571105 0.50835754 0.50948481 0.51857988 0.50894112 0.51106906
 0.50762786 0.50903099 0.52678718 0.51546564 0.49830309 0.50383375
 0.50936391 0.52236156 0.52684589 0.54328289 0.59054396 0.54961483
 0.58720323]
INFO:root:auroc_mean
INFO:root:0.5270031158765471
INFO:root:auprc_mean
INFO:root:0.1995505545084236
INFO:root:auprc_scores
INFO:root:[0.29085965 0.10570761 0.08104449 0.33788925 0.21172055 0.14908685
 0.19794972 0.10285139 0.26105126 0.32428139 0.11712832 0.17819812
 0.41088638 0.42273818 0.39283621 0.07604836 0.21495756 0.13104872
 0.09874012 0.05465561 0.07376099 0.14839566 0.22589799 0.19268414
 0.18834535]
INFO:root:ci_auroc
INFO:root:[(0.5260396369719889, 0.538221916440997), (0.6115806423830928, 0.6392330848581559), (0.5025998109835659, 0.5239300209054166), (0.5110612460268441, 0.5224739700495065), (0.5036553926342223, 0.516858793856851), (0.5057091099487091, 0.52142256959668), (0.5087897327772829, 0.5226477151642919), (0.49894819998801404, 0.5172845741341128), (0.5034050253166764, 0.5156833562885826), (0.5130423896246249, 0.5245005167725031), (0.4998078313984917, 0.51732091661594), (0.5035622649663366, 0.5182603926706713), (0.5013143559314377, 0.5134049529578902), (0.5031232182961192, 0.5146473527631368), (0.5210152397584733, 0.5324727171535171), (0.5037723912618448, 0.5267812915931936), (0.4915053090608418, 0.5047443116279063), (0.4958282456245113, 0.5130851540198956), (0.5000704980186944, 0.51907532542953), (0.5083753685320233, 0.5354100105263985), (0.5158787142078661, 0.5380752712775524), (0.5341860749655893, 0.5515937891784398), (0.5830220861535287, 0.5982162404905045), (0.5422581265314048, 0.5571449065388314), (0.578271216654176, 0.5959628891270733)]
INFO:root:ci_auprc
INFO:root:[(0.2844636565753287, 0.2975161846595523), (0.09835727845506817, 0.11375550528449381), (0.07726065773528278, 0.08553380594171475), (0.33136518437191886, 0.3442078268803174), (0.20605866348630306, 0.21717848751376043), (0.1444029268055512, 0.15401364828247147), (0.19264747180694108, 0.20345699179285517), (0.09850415679256946, 0.10736484279890829), (0.2553044248038487, 0.2671685634839168), (0.3185216151364276, 0.33122753753340634), (0.11320819606772141, 0.12181355765846925), (0.17305104587022876, 0.1835883211093994), (0.40421906740988084, 0.41775607216551336), (0.41561641705615565, 0.4296312263318627), (0.38591134193456283, 0.4004088645168999), (0.07250236888096097, 0.0805750853122238), (0.20921281554150287, 0.22098692764764258), (0.12670832429934925, 0.1366255353109069), (0.09486544567567369, 0.1030662399184993), (0.05142000780441614, 0.05864038873017765), (0.06997163188270214, 0.07804788766541329), (0.14245250664506842, 0.1541005868112349), (0.219184019942233, 0.2345063059121673), (0.18640953720762382, 0.19992764518119974), (0.18070259913504813, 0.19668173486028237)]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
INFO:root:val epoch: 0
INFO:root:val epoch: 1
INFO:root:val epoch: 2
INFO:root:val epoch: 3
INFO:root:val epoch: 4
INFO:root:val epoch: 5
INFO:root:val epoch: 6
INFO:root:val epoch: 7
INFO:root:val epoch: 8
INFO:root:val epoch: 9
INFO:root:val epoch: 10
INFO:root:val epoch: 11
INFO:root:val epoch: 12
INFO:root:val epoch: 13
INFO:root:val epoch: 14
INFO:root:val epoch: 15
INFO:root:val epoch: 16
INFO:root:val epoch: 17
INFO:root:val epoch: 18
INFO:root:val epoch: 19
INFO:root:val epoch: 20
INFO:root:val epoch: 21
INFO:root:val epoch: 22
INFO:root:val epoch: 23
INFO:root:val epoch: 24
INFO:root:val epoch: 25
INFO:root:val epoch: 26
INFO:root:val epoch: 27
INFO:root:val epoch: 28
INFO:root:val epoch: 29
INFO:root:val epoch: 30
INFO:root:val epoch: 31
INFO:root:val epoch: 32
INFO:root:val epoch: 33
INFO:root:val epoch: 34
INFO:root:val epoch: 35
INFO:root:val epoch: 36
INFO:root:val metrics
INFO:root:auc_scores
INFO:root:[0.60248022 0.74688017 0.59103391 0.56753667 0.53142607 0.56908989
 0.59227791 0.56320252 0.5863943  0.59886602 0.6029575  0.55341142
 0.5638894  0.54645871 0.58886997 0.55293952 0.54578924 0.56207535
 0.56196282 0.58115722 0.6134094  0.65258788 0.71318453 0.63661836
 0.67685493]
INFO:root:auroc_mean
INFO:root:0.5960541572867338
INFO:root:auprc_mean
INFO:root:0.24612875055033068
INFO:root:auprc_scores
INFO:root:[0.37152303 0.14634847 0.10266228 0.35263289 0.22697331 0.17336158
 0.24810588 0.12729166 0.3160459  0.3984342  0.16029808 0.19808558
 0.45853459 0.44582905 0.47513004 0.08400897 0.24169653 0.17459999
 0.11897549 0.07968782 0.09909306 0.21182578 0.3328326  0.28966819
 0.3195738 ]
INFO:root:ci_auroc
INFO:root:[(0.5835926062925972, 0.6205212782573107), (0.7128802455906705, 0.7780798023932536), (0.5599759110356712, 0.6215587542466612), (0.5502164334641907, 0.585899078444976), (0.5107630744213225, 0.5527188662926331), (0.5470464731411777, 0.5919024059890455), (0.5696261859018064, 0.6141247992495534), (0.5381565286306688, 0.5902112265292505), (0.5694425676514082, 0.6059932647467933), (0.5819826929263108, 0.6147527048876162), (0.5795745003948601, 0.6276993825338907), (0.5304314054417075, 0.5754416328024702), (0.5476738848871356, 0.5812494578707575), (0.5306584867623473, 0.5642082107977221), (0.5718484822181286, 0.6058527783476704), (0.5233237598979729, 0.5838147580132554), (0.5254178251214138, 0.5653277862288969), (0.5355786987669948, 0.585914286653724), (0.5329324706743729, 0.5902872195922736), (0.5447985857942462, 0.6158353340870211), (0.5782203311655468, 0.6456387691912687), (0.6283383698469327, 0.6774325017309604), (0.6940227450382925, 0.7330369417265694), (0.6113861912061885, 0.6589251091740709), (0.6505578660319712, 0.6998019152827973)]
INFO:root:ci_auprc
INFO:root:[(0.34472459043751463, 0.3994550286159411), (0.11837813487259242, 0.18800950349525114), (0.08907298756098653, 0.12231677230357485), (0.33285795521145073, 0.37442083584916924), (0.2094901378512059, 0.2467588196917452), (0.1576218567946124, 0.19350182912906844), (0.22790725144344023, 0.26946536675135174), (0.1138892207607103, 0.14612223703345506), (0.29586766949250304, 0.3389766056071941), (0.3766018112258819, 0.4208173730256549), (0.14405111487574715, 0.1810584513360225), (0.18144723739933988, 0.21659500899029624), (0.43880873938424425, 0.48057470369389566), (0.4246088004213945, 0.4688743043326094), (0.45215178921006194, 0.4991350586484286), (0.07026914013240552, 0.10537651398778704), (0.22319361617817562, 0.26160600127414513), (0.15305355267935858, 0.20224734950027523), (0.10433062484091665, 0.13721746790929706), (0.06512447913784908, 0.09954728765894548), (0.08554895986785327, 0.12007351247856479), (0.18858788704848767, 0.24059567632361814), (0.304696329089372, 0.3658021520567379), (0.2580254437077909, 0.3258071499027783), (0.28106459386908555, 0.3608061828776813)]
mefuse_linear_eval.py:348: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  inputs, labels = torch.tensor(data[0]).to(device), torch.tensor(data[1]).to(device)
